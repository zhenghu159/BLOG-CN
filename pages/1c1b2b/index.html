<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>文献阅读 --- Toward data-efficient learning：A benchmark for COVID-19 CT lung and infection segmentation | TigerZ Blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="shortcut icon" href="/img/favicon.ico">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_3114978_qe0b39no76.css">
    <noscript><meta http-equiv="refresh" content="0; url=https://www.youngkbt.cn/noscript/"><style>.theme-vdoing-content { display:none }</noscript>
    <script src="https://cdn.staticfile.org/twikoo/1.6.7/twikoo.all.min.js"></script>
    <script>var _hmt = _hmt || [];
          (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?267c5680c2ffb468ca29c45ffe6801da"; 
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
          })();
          </script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    <meta name="description" content="TigerZ个人博客, VuePress搭建, 使用了 Vdoing 主题。">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="keywords" content="TigerZ个人博客, VuePress搭建。">
    <meta name="theme-color" content="#11a8cd">
    <meta name="baidu-site-verification" content="codeva-nuy0c96SLu">
    
    <link rel="preload" href="/assets/css/0.styles.d72a9179.css" as="style"><link rel="preload" href="/assets/js/app.135a3dc6.js" as="script"><link rel="preload" href="/assets/js/2.b95133a4.js" as="script"><link rel="preload" href="/assets/js/125.ffbca55f.js" as="script"><link rel="preload" href="/assets/js/14.330b018e.js" as="script"><link rel="preload" href="/assets/js/4.17f28c7e.js" as="script"><link rel="preload" href="/assets/js/8.113240f8.js" as="script"><link rel="preload" href="/assets/js/11.6804d4e2.js" as="script"><link rel="prefetch" href="/assets/js/10.3a38bc3c.js"><link rel="prefetch" href="/assets/js/100.07ad7c69.js"><link rel="prefetch" href="/assets/js/101.cf0e9c52.js"><link rel="prefetch" href="/assets/js/102.b677846a.js"><link rel="prefetch" href="/assets/js/103.d978cd23.js"><link rel="prefetch" href="/assets/js/104.aaca6a9e.js"><link rel="prefetch" href="/assets/js/105.b70bc017.js"><link rel="prefetch" href="/assets/js/106.6357bc2a.js"><link rel="prefetch" href="/assets/js/107.52ba7c90.js"><link rel="prefetch" href="/assets/js/108.9bdac9ca.js"><link rel="prefetch" href="/assets/js/109.0424b457.js"><link rel="prefetch" href="/assets/js/110.5e8624f2.js"><link rel="prefetch" href="/assets/js/111.9f280b10.js"><link rel="prefetch" href="/assets/js/112.e3e184c2.js"><link rel="prefetch" href="/assets/js/113.9dc61991.js"><link rel="prefetch" href="/assets/js/114.6a888a2a.js"><link rel="prefetch" href="/assets/js/115.0c868c7e.js"><link rel="prefetch" href="/assets/js/116.5f982486.js"><link rel="prefetch" href="/assets/js/117.05d64b6c.js"><link rel="prefetch" href="/assets/js/118.de1820da.js"><link rel="prefetch" href="/assets/js/119.9e48d583.js"><link rel="prefetch" href="/assets/js/12.5dfbdbbd.js"><link rel="prefetch" href="/assets/js/120.e79c6680.js"><link rel="prefetch" href="/assets/js/121.9d3d53fd.js"><link rel="prefetch" href="/assets/js/122.7704c3e0.js"><link rel="prefetch" href="/assets/js/123.1d7bd3ac.js"><link rel="prefetch" href="/assets/js/124.66f0d159.js"><link rel="prefetch" href="/assets/js/126.faa2bafe.js"><link rel="prefetch" href="/assets/js/127.4cd6096d.js"><link rel="prefetch" href="/assets/js/128.c063ce35.js"><link rel="prefetch" href="/assets/js/129.6ff200b7.js"><link rel="prefetch" href="/assets/js/13.0fa098c9.js"><link rel="prefetch" href="/assets/js/130.bd3a34a0.js"><link rel="prefetch" href="/assets/js/131.b1d386f6.js"><link rel="prefetch" href="/assets/js/132.f2e1f89a.js"><link rel="prefetch" href="/assets/js/133.0dd4a6e4.js"><link rel="prefetch" href="/assets/js/134.03528a2c.js"><link rel="prefetch" href="/assets/js/135.5f50f01f.js"><link rel="prefetch" href="/assets/js/136.6038686c.js"><link rel="prefetch" href="/assets/js/137.c3668c24.js"><link rel="prefetch" href="/assets/js/138.52048225.js"><link rel="prefetch" href="/assets/js/139.8a83e4a5.js"><link rel="prefetch" href="/assets/js/140.0c9bf078.js"><link rel="prefetch" href="/assets/js/141.bd662f0c.js"><link rel="prefetch" href="/assets/js/142.03c93ff2.js"><link rel="prefetch" href="/assets/js/143.d81dbfa4.js"><link rel="prefetch" href="/assets/js/144.e2baf63f.js"><link rel="prefetch" href="/assets/js/145.bbc19ffd.js"><link rel="prefetch" href="/assets/js/146.c8bad20d.js"><link rel="prefetch" href="/assets/js/147.76385b63.js"><link rel="prefetch" href="/assets/js/148.0f773ba8.js"><link rel="prefetch" href="/assets/js/149.06f2933d.js"><link rel="prefetch" href="/assets/js/15.b8bb4a86.js"><link rel="prefetch" href="/assets/js/150.80df8c58.js"><link rel="prefetch" href="/assets/js/151.3d18fd70.js"><link rel="prefetch" href="/assets/js/152.2e71a772.js"><link rel="prefetch" href="/assets/js/153.0b4b3e96.js"><link rel="prefetch" href="/assets/js/154.10e02163.js"><link rel="prefetch" href="/assets/js/155.7c69bdf4.js"><link rel="prefetch" href="/assets/js/156.660f1ea4.js"><link rel="prefetch" href="/assets/js/157.b0c3c63c.js"><link rel="prefetch" href="/assets/js/158.2d79cfc7.js"><link rel="prefetch" href="/assets/js/159.839ca4dd.js"><link rel="prefetch" href="/assets/js/16.781d3ca8.js"><link rel="prefetch" href="/assets/js/160.4c0aa430.js"><link rel="prefetch" href="/assets/js/161.26031b01.js"><link rel="prefetch" href="/assets/js/162.7382ebc3.js"><link rel="prefetch" href="/assets/js/163.1b782d65.js"><link rel="prefetch" href="/assets/js/164.29f66df7.js"><link rel="prefetch" href="/assets/js/165.aefb0b28.js"><link rel="prefetch" href="/assets/js/166.5a1e69d1.js"><link rel="prefetch" href="/assets/js/167.9ec8f2b4.js"><link rel="prefetch" href="/assets/js/168.8e72cb0f.js"><link rel="prefetch" href="/assets/js/169.00457935.js"><link rel="prefetch" href="/assets/js/17.14bdc8cc.js"><link rel="prefetch" href="/assets/js/170.02889291.js"><link rel="prefetch" href="/assets/js/171.18d34ca2.js"><link rel="prefetch" href="/assets/js/172.9eead420.js"><link rel="prefetch" href="/assets/js/173.526e718c.js"><link rel="prefetch" href="/assets/js/174.7b94dd0c.js"><link rel="prefetch" href="/assets/js/175.b34180db.js"><link rel="prefetch" href="/assets/js/176.df484597.js"><link rel="prefetch" href="/assets/js/177.bd35bd12.js"><link rel="prefetch" href="/assets/js/178.c0a11a10.js"><link rel="prefetch" href="/assets/js/179.e31946e2.js"><link rel="prefetch" href="/assets/js/18.14ae8e93.js"><link rel="prefetch" href="/assets/js/180.764682cc.js"><link rel="prefetch" href="/assets/js/181.977f1390.js"><link rel="prefetch" href="/assets/js/182.2692f937.js"><link rel="prefetch" href="/assets/js/183.e8af2276.js"><link rel="prefetch" href="/assets/js/184.b4e1ac36.js"><link rel="prefetch" href="/assets/js/185.6e4ecc97.js"><link rel="prefetch" href="/assets/js/186.989245c1.js"><link rel="prefetch" href="/assets/js/187.80231977.js"><link rel="prefetch" href="/assets/js/188.d083d8df.js"><link rel="prefetch" href="/assets/js/189.26567c30.js"><link rel="prefetch" href="/assets/js/19.bb80f057.js"><link rel="prefetch" href="/assets/js/190.3873532c.js"><link rel="prefetch" href="/assets/js/191.05e3fbd2.js"><link rel="prefetch" href="/assets/js/192.4b8ea243.js"><link rel="prefetch" href="/assets/js/193.28a8daba.js"><link rel="prefetch" href="/assets/js/194.d573e176.js"><link rel="prefetch" href="/assets/js/195.8f7be313.js"><link rel="prefetch" href="/assets/js/196.e671f76e.js"><link rel="prefetch" href="/assets/js/197.fd0b0e77.js"><link rel="prefetch" href="/assets/js/198.9d6d57a8.js"><link rel="prefetch" href="/assets/js/199.b01e4408.js"><link rel="prefetch" href="/assets/js/20.04e82b51.js"><link rel="prefetch" href="/assets/js/200.41fbcbdb.js"><link rel="prefetch" href="/assets/js/201.112b825c.js"><link rel="prefetch" href="/assets/js/202.78dabbb8.js"><link rel="prefetch" href="/assets/js/203.d712629e.js"><link rel="prefetch" href="/assets/js/204.3244b025.js"><link rel="prefetch" href="/assets/js/205.20d2a208.js"><link rel="prefetch" href="/assets/js/21.2bb87dd4.js"><link rel="prefetch" href="/assets/js/22.9f6217ab.js"><link rel="prefetch" href="/assets/js/23.5e274244.js"><link rel="prefetch" href="/assets/js/24.b9574f9e.js"><link rel="prefetch" href="/assets/js/25.137ded62.js"><link rel="prefetch" href="/assets/js/26.875ef211.js"><link rel="prefetch" href="/assets/js/27.21478680.js"><link rel="prefetch" href="/assets/js/28.a17d8c74.js"><link rel="prefetch" href="/assets/js/29.82ee0284.js"><link rel="prefetch" href="/assets/js/3.3abf1aa3.js"><link rel="prefetch" href="/assets/js/30.f0a41074.js"><link rel="prefetch" href="/assets/js/31.67a239e0.js"><link rel="prefetch" href="/assets/js/32.2a07296f.js"><link rel="prefetch" href="/assets/js/33.3c91d254.js"><link rel="prefetch" href="/assets/js/34.fedaa0c2.js"><link rel="prefetch" href="/assets/js/35.b2bf202a.js"><link rel="prefetch" href="/assets/js/36.ba0c39cd.js"><link rel="prefetch" href="/assets/js/37.6c5d6dea.js"><link rel="prefetch" href="/assets/js/38.6898e0d0.js"><link rel="prefetch" href="/assets/js/39.51032bd3.js"><link rel="prefetch" href="/assets/js/40.54330115.js"><link rel="prefetch" href="/assets/js/41.0e5fc4df.js"><link rel="prefetch" href="/assets/js/42.b8579e68.js"><link rel="prefetch" href="/assets/js/43.f0d87263.js"><link rel="prefetch" href="/assets/js/44.dadf352d.js"><link rel="prefetch" href="/assets/js/45.48126a39.js"><link rel="prefetch" href="/assets/js/46.daffcf96.js"><link rel="prefetch" href="/assets/js/47.910b1864.js"><link rel="prefetch" href="/assets/js/48.ef8b1d7c.js"><link rel="prefetch" href="/assets/js/49.627389f0.js"><link rel="prefetch" href="/assets/js/5.ff06ff0e.js"><link rel="prefetch" href="/assets/js/50.a8db01db.js"><link rel="prefetch" href="/assets/js/51.7ee63ade.js"><link rel="prefetch" href="/assets/js/52.704a676f.js"><link rel="prefetch" href="/assets/js/53.885a2d7c.js"><link rel="prefetch" href="/assets/js/54.15136c57.js"><link rel="prefetch" href="/assets/js/55.86145f9f.js"><link rel="prefetch" href="/assets/js/56.619fcbc5.js"><link rel="prefetch" href="/assets/js/57.d5ab5e8b.js"><link rel="prefetch" href="/assets/js/58.ed36b9cb.js"><link rel="prefetch" href="/assets/js/59.a6d66110.js"><link rel="prefetch" href="/assets/js/6.78d855d4.js"><link rel="prefetch" href="/assets/js/60.80777eb6.js"><link rel="prefetch" href="/assets/js/61.e0ad0e0b.js"><link rel="prefetch" href="/assets/js/62.170fe53a.js"><link rel="prefetch" href="/assets/js/63.987c67c8.js"><link rel="prefetch" href="/assets/js/64.d110743c.js"><link rel="prefetch" href="/assets/js/65.b891a616.js"><link rel="prefetch" href="/assets/js/66.f0afa649.js"><link rel="prefetch" href="/assets/js/67.a2999e6f.js"><link rel="prefetch" href="/assets/js/68.4304a9a3.js"><link rel="prefetch" href="/assets/js/69.ca4ccc73.js"><link rel="prefetch" href="/assets/js/7.ca82cfad.js"><link rel="prefetch" href="/assets/js/70.82988a8d.js"><link rel="prefetch" href="/assets/js/71.c647d9ae.js"><link rel="prefetch" href="/assets/js/72.1a7bd048.js"><link rel="prefetch" href="/assets/js/73.d0d8f205.js"><link rel="prefetch" href="/assets/js/74.2487173f.js"><link rel="prefetch" href="/assets/js/75.96c44e6a.js"><link rel="prefetch" href="/assets/js/76.97334731.js"><link rel="prefetch" href="/assets/js/77.0f523633.js"><link rel="prefetch" href="/assets/js/78.a2b1b565.js"><link rel="prefetch" href="/assets/js/79.bc117446.js"><link rel="prefetch" href="/assets/js/80.e9de3364.js"><link rel="prefetch" href="/assets/js/81.de3e1a8d.js"><link rel="prefetch" href="/assets/js/82.d6b092b3.js"><link rel="prefetch" href="/assets/js/83.480ad2a7.js"><link rel="prefetch" href="/assets/js/84.9ccf3129.js"><link rel="prefetch" href="/assets/js/85.d3b4c265.js"><link rel="prefetch" href="/assets/js/86.a9d37445.js"><link rel="prefetch" href="/assets/js/87.87970e32.js"><link rel="prefetch" href="/assets/js/88.ae6c8b1a.js"><link rel="prefetch" href="/assets/js/89.004ff48b.js"><link rel="prefetch" href="/assets/js/9.ea9f0c60.js"><link rel="prefetch" href="/assets/js/90.574ad6dc.js"><link rel="prefetch" href="/assets/js/91.919f7599.js"><link rel="prefetch" href="/assets/js/92.0403f50b.js"><link rel="prefetch" href="/assets/js/93.f1c10d6e.js"><link rel="prefetch" href="/assets/js/94.68180157.js"><link rel="prefetch" href="/assets/js/95.43aaa156.js"><link rel="prefetch" href="/assets/js/96.5c07dd45.js"><link rel="prefetch" href="/assets/js/97.34e6505b.js"><link rel="prefetch" href="/assets/js/98.ee88afe4.js"><link rel="prefetch" href="/assets/js/99.d636b596.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d72a9179.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">TigerZ Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/navigation/" class="nav-link">导航站</a></div><div class="nav-item"><a href="/pages/585994/" class="nav-link">科研技能</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文献阅读" class="dropdown-title"><a href="/pages/577e62/" class="link-title">文献阅读</a> <span class="title" style="display:none;">文献阅读</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/09e806/" class="nav-link">作者汇总</a></li><li class="dropdown-subitem"><a href="/pages/4c56e7/" class="nav-link">文献汇总</a></li></ul></li><li class="dropdown-item"><h4>分类</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/17c432/" class="nav-link">神经生物学</a></li><li class="dropdown-subitem"><a href="/pages/e2e6a4/" class="nav-link">单细胞空间组</a></li><li class="dropdown-subitem"><a href="/pages/e90196/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/69dc52/" class="nav-link">生物信息学</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生信学习" class="dropdown-title"><a href="/pages/98350d/" class="link-title">生信学习</a> <span class="title" style="display:none;">生信学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/11a817/" class="nav-link">生信工具汇总</a></li></ul></li><li class="dropdown-item"><h4>生信工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/967a30/" class="nav-link">单细胞和空间组</a></li><li class="dropdown-subitem"><a href="/pages/3c3418/" class="nav-link">机器学习</a></li><li class="dropdown-subitem"><a href="/pages/726c78/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/8b01b8/" class="nav-link">图像处理</a></li><li class="dropdown-subitem"><a href="/pages/c3f74c/" class="nav-link">NGS相关</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Web开发" class="dropdown-title"><a href="/pages/4efbc6/" class="link-title">Web开发</a> <span class="title" style="display:none;">Web开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/3ca8f4/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/pages/f16f8d/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/pages/9ec206/" class="nav-link">JS/TS</a></li><li class="dropdown-subitem"><a href="/pages/1abc5f/" class="nav-link">Markdown</a></li><li class="dropdown-subitem"><a href="/pages/d2038c/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/pages/d4684b/" class="nav-link">Ajax</a></li></ul></li><li class="dropdown-item"><h4>后端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/98c9ed/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/pages/e1436c/" class="nav-link">Django</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据分析" class="dropdown-title"><a href="/pages/3c0f51/" class="link-title">数据分析</a> <span class="title" style="display:none;">数据分析</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/01057a/" class="nav-link">数学基础</a></li><li class="dropdown-item"><h4>机器学习</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/99a1ec/" class="nav-link">机器学习 - 西瓜书</a></li><li class="dropdown-subitem"><a href="/pages/7daf99/" class="nav-link">机器学习 - 吴恩达</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程学习" class="dropdown-title"><a href="/pages/baed44/" class="link-title">编程学习</a> <span class="title" style="display:none;">编程学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/9ab953/" class="nav-link">R 汇总</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生物知识" class="dropdown-title"><a href="/pages/634e82/" class="link-title">生物知识</a> <span class="title" style="display:none;">生物知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>神经生物学</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/be5d67/" class="nav-link">《神经生物学》- 丁斐</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生活" class="dropdown-title"><a href="/pages/d28eb7/" class="link-title">生活</a> <span class="title" style="display:none;">生活</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/eccd67/" class="nav-link">观影</a></li><li class="dropdown-item"><!----> <a href="/pages/30653b/" class="nav-link">摘抄</a></li><li class="dropdown-item"><!----> <a href="/pages/1a58a6/" class="nav-link">音乐</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="关于" class="dropdown-title"><a href="/pages/8cb41f/" class="link-title">关于</a> <span class="title" style="display:none;">关于</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/13ae7d/" class="nav-link">关于 - 自我</a></li><li class="dropdown-item"><!----> <a href="/pages/2b095a/" class="nav-link">关于 - 本站</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">关于 - 归档</a></li></ul></div></div><div class="nav-item"><a href="/message-area/" class="nav-link">留言区</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="img/avatar.jpg"> <div class="blogger-info"><h3>TigerZ</h3> <span>一个努力学习的小菜鸡</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/navigation/" class="nav-link">导航站</a></div><div class="nav-item"><a href="/pages/585994/" class="nav-link">科研技能</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文献阅读" class="dropdown-title"><a href="/pages/577e62/" class="link-title">文献阅读</a> <span class="title" style="display:none;">文献阅读</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/09e806/" class="nav-link">作者汇总</a></li><li class="dropdown-subitem"><a href="/pages/4c56e7/" class="nav-link">文献汇总</a></li></ul></li><li class="dropdown-item"><h4>分类</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/17c432/" class="nav-link">神经生物学</a></li><li class="dropdown-subitem"><a href="/pages/e2e6a4/" class="nav-link">单细胞空间组</a></li><li class="dropdown-subitem"><a href="/pages/e90196/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/69dc52/" class="nav-link">生物信息学</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生信学习" class="dropdown-title"><a href="/pages/98350d/" class="link-title">生信学习</a> <span class="title" style="display:none;">生信学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/11a817/" class="nav-link">生信工具汇总</a></li></ul></li><li class="dropdown-item"><h4>生信工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/967a30/" class="nav-link">单细胞和空间组</a></li><li class="dropdown-subitem"><a href="/pages/3c3418/" class="nav-link">机器学习</a></li><li class="dropdown-subitem"><a href="/pages/726c78/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/8b01b8/" class="nav-link">图像处理</a></li><li class="dropdown-subitem"><a href="/pages/c3f74c/" class="nav-link">NGS相关</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Web开发" class="dropdown-title"><a href="/pages/4efbc6/" class="link-title">Web开发</a> <span class="title" style="display:none;">Web开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/3ca8f4/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/pages/f16f8d/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/pages/9ec206/" class="nav-link">JS/TS</a></li><li class="dropdown-subitem"><a href="/pages/1abc5f/" class="nav-link">Markdown</a></li><li class="dropdown-subitem"><a href="/pages/d2038c/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/pages/d4684b/" class="nav-link">Ajax</a></li></ul></li><li class="dropdown-item"><h4>后端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/98c9ed/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/pages/e1436c/" class="nav-link">Django</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据分析" class="dropdown-title"><a href="/pages/3c0f51/" class="link-title">数据分析</a> <span class="title" style="display:none;">数据分析</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/01057a/" class="nav-link">数学基础</a></li><li class="dropdown-item"><h4>机器学习</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/99a1ec/" class="nav-link">机器学习 - 西瓜书</a></li><li class="dropdown-subitem"><a href="/pages/7daf99/" class="nav-link">机器学习 - 吴恩达</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程学习" class="dropdown-title"><a href="/pages/baed44/" class="link-title">编程学习</a> <span class="title" style="display:none;">编程学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/9ab953/" class="nav-link">R 汇总</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生物知识" class="dropdown-title"><a href="/pages/634e82/" class="link-title">生物知识</a> <span class="title" style="display:none;">生物知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>神经生物学</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/be5d67/" class="nav-link">《神经生物学》- 丁斐</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生活" class="dropdown-title"><a href="/pages/d28eb7/" class="link-title">生活</a> <span class="title" style="display:none;">生活</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/eccd67/" class="nav-link">观影</a></li><li class="dropdown-item"><!----> <a href="/pages/30653b/" class="nav-link">摘抄</a></li><li class="dropdown-item"><!----> <a href="/pages/1a58a6/" class="nav-link">音乐</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="关于" class="dropdown-title"><a href="/pages/8cb41f/" class="link-title">关于</a> <span class="title" style="display:none;">关于</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/13ae7d/" class="nav-link">关于 - 自我</a></li><li class="dropdown-item"><!----> <a href="/pages/2b095a/" class="nav-link">关于 - 本站</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">关于 - 归档</a></li></ul></div></div><div class="nav-item"><a href="/message-area/" class="nav-link">留言区</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>神经生物学</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>单细胞空间组</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>三维基因组</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>生物信息学</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/ffdcc0/" class="sidebar-link">文献阅读 --- WGCNA：an R package for weighted correlation network analysis</a></li><li><a href="/pages/0d1fce/" class="sidebar-link">文献阅读 --- Spatial reconstruction of single-cell gene expression data</a></li><li><a href="/pages/e020de/" class="sidebar-link">文献阅读 --- An interactive framework for whole-brain maps at cellular resolution</a></li><li><a href="/pages/ebb632/" class="sidebar-link">文献阅读 --- SCANPY：large-scale single-cell gene expression data analysis</a></li><li><a href="/pages/f37280/" class="sidebar-link">文献阅读 --- Integrating single-cell transcriptomic data across different conditions, technologies, and species</a></li><li><a href="/pages/06c5a0/" class="sidebar-link">文献阅读 --- Recovering Gene Interactions from Single-Cell Data Using Data Diffusion</a></li><li><a href="/pages/71b694/" class="sidebar-link">文献阅读 --- DoubletFinder:Doublet Detection in Single-Cell RNA Sequencing Data Using Artificial Nearest Neighbors</a></li><li><a href="/pages/d26f9e/" class="sidebar-link">文献阅读 --- Comprehensive Integration of Single-Cell Data</a></li><li><a href="/pages/c7adb0/" class="sidebar-link">文献阅读 --- A systematic evaluation of single-cell RNA-sequencing imputation methods</a></li><li><a href="/pages/d38252/" class="sidebar-link">文献阅读 --- nnU-Net：a self-configuring method for deep learning-based biomedical image segmentation</a></li><li><a href="/pages/c34d2c/" class="sidebar-link">文献阅读 --- GCNG：graph convolutional networks for inferring gene interaction from spatial transcriptomics data</a></li><li><a href="/pages/1f3ea0/" class="sidebar-link">文献阅读 --- Cellpose：a generalist algorithm for cellular segmentation</a></li><li><a href="/pages/1f53c5/" class="sidebar-link">文献阅读 --- FAN-C:a feature-rich framework for the analysis and visualisation of chromosome conformation capture data</a></li><li><a href="/pages/1c1b2b/" aria-current="page" class="active sidebar-link">文献阅读 --- Toward data-efficient learning：A benchmark for COVID-19 CT lung and infection segmentation</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/1c1b2b/#abstract" class="sidebar-link">Abstract</a></li><li class="sidebar-sub-header level2"><a href="/pages/1c1b2b/#_1-introduction" class="sidebar-link">1. INTRODUCTION</a></li><li class="sidebar-sub-header level2"><a href="/pages/1c1b2b/#_2-materials" class="sidebar-link">2. MATERIALS</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_2-a-现有的肺-ct-分割数据集" class="sidebar-link">2.A. 现有的肺 CT 分割数据集</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_2-a-1-structseg-肺器官分割" class="sidebar-link">2.A.1. StructSeg 肺器官分割</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_2-a-2-nsclc-左右肺分割" class="sidebar-link">2.A.2. NSCLC 左右肺分割</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_2-b-现有的肺病变-ct-分割数据集" class="sidebar-link">2.B. 现有的肺病变 CT 分割数据集</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_2-b-1-msd-肺肿瘤分割" class="sidebar-link">2.B.1. MSD 肺肿瘤分割</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_2-b-2-structseg-肺癌的总靶体积分割" class="sidebar-link">2.B.2. StructSeg 肺癌的总靶体积分割</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_2-b-3-nsclc-胸腔积液-pe-分割" class="sidebar-link">2.B.3. NSCLC 胸腔积液（PE）分割</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_2-b-4-mosmed-dataset" class="sidebar-link">2.B.4. MosMed dataset</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_2-c-我们的-covid-19-ct-seg-数据集" class="sidebar-link">2.C. 我们的 COVID-19-CT-Seg 数据集</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/1c1b2b/#_3-methods" class="sidebar-link">3. METHODS</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_3-a-task-1-使用有限的注释进行学习" class="sidebar-link">3.A. Task 1: 使用有限的注释进行学习</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_3-b-task-2-学习将-covid-19-ct-扫描与非-covid-19-ct-扫描进行分割" class="sidebar-link">3.B. Task 2: 学习将 COVID-19 CT 扫描与非 COVID-19 CT 扫描进行分割</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_3-c-task-3-同时学习-covid-19-和-non-covid-19-ct-扫描" class="sidebar-link">3.C. Task 3: 同时学习 COVID-19 和 non-COVID-19 CT 扫描</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_3-d-评价指标" class="sidebar-link">3.D. 评价指标</a></li><li class="sidebar-sub-header level4"><a href="/pages/1c1b2b/#_3-d-1-基于区域的度量" class="sidebar-link">3.D.1. 基于区域的度量</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_3-d-2-基于边界的测量" class="sidebar-link">3.D.2. 基于边界的测量</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_3-e-u-net-baselines-oldies-but-goldies" class="sidebar-link">3.E. U-Net baselines: Oldies but goldies</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/1c1b2b/#_4-results-and-discussion" class="sidebar-link">4. RESULTS AND DISCUSSION</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_4-a-results-of-task-1-使用有限的注释进行学习" class="sidebar-link">4.A. Results of task 1: 使用有限的注释进行学习</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_4-b-results-of-task-2-学习将-covid-19-ct-扫描与-non-covid-19-ct-扫描分割" class="sidebar-link">4.B. Results of task 2: 学习将 COVID- 19 CT 扫描与 non-COVID-19 CT 扫描分割</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_4-c-results-of-task-3-同时学习-covid-19-和-non-covid-19ct-扫描" class="sidebar-link">4.C. Results of task 3: 同时学习 COVID-19 和 non-COVID-19CT 扫描</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_4-d-不同任务之间的比较" class="sidebar-link">4.D. 不同任务之间的比较</a></li><li class="sidebar-sub-header level3"><a href="/pages/1c1b2b/#_4-e-limitation" class="sidebar-link">4.E. Limitation</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/1c1b2b/#_5-conclusion" class="sidebar-link">5. CONCLUSION</a></li></ul></li><li><a href="/pages/2737d2/" class="sidebar-link">文献阅读 --- Inference and analysis of cell-cell communication using CellChat</a></li><li><a href="/pages/b4dfe0/" class="sidebar-link">文献阅读 --- Integrated analysis of multimodal single-cell data</a></li><li><a href="/pages/6a4bcc/" class="sidebar-link">文献阅读 --- Discovery and Validation of Key Biomarkers Based on Immune Infiltrates in Alzheimer's Disease</a></li><li><a href="/pages/c3bbd9/" class="sidebar-link">文献阅读 --- Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram</a></li><li><a href="/pages/9912cc/" class="sidebar-link">文献阅读 --- Cell2location maps fine-grained cell types in spatial transcriptomics</a></li><li><a href="/pages/76476f/" class="sidebar-link">文献阅读 --- Squidpy：a scalable framework for spatial omics analysis</a></li><li><a href="/pages/112d0b/" class="sidebar-link">文献阅读 --- Viv：multiscale visualization of high-resolution multiplexed bioimaging data on the web</a></li><li><a href="/pages/4cba92/" class="sidebar-link">文献阅读 --- SpaceX：gene co-expression network estimation for spatial transcriptomics</a></li><li><a href="/pages/794f06/" class="sidebar-link">文献阅读 --- Inferring neuron-neuron communications from single-cell transcriptomics through NeuronChat</a></li><li><a href="/pages/8c5839/" class="sidebar-link">文献阅读 --- Dictionary learning for integrative, multimodal and scalable single-cell analysis</a></li><li><a href="/pages/124edd/" class="sidebar-link">文献阅读 --- The scverse project provides a computational ecosystem for single-cell omics data analysis</a></li><li><a href="/pages/a24249/" class="sidebar-link">文献阅读 --- hdWGCNA identifies co-expression networks in high-dimensional transcriptomics data</a></li><li><a href="/pages/da0fb5/" class="sidebar-link">文献阅读 --- SPACEL：deep learning-based characterization of spatial transcriptome architectures</a></li><li><a href="/pages/32a729/" class="sidebar-link">文献阅读 --- The tidyomics ecosystem：enhancing omic data analyses</a></li><li><a href="/pages/02ef79/" class="sidebar-link">文献阅读 --- ezSingleCell：an integrated one-stop single-cell and spatial omics analysis platform for bench scientists</a></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-1"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/pages/577e62/#文献阅读" data-v-06225672>文献阅读</a></li><li data-v-06225672><a href="/pages/577e62/#生物信息学" data-v-06225672>生物信息学</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://zhenghu159.github.io/" target="_blank" title="作者" class="beLink" data-v-06225672>TigerZ </a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-03-27</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">文献阅读 --- Toward data-efficient learning：A benchmark for COVID-19 CT lung and infection segmentation<!----></h1>  <div class="theme-vdoing-content content__default"><p>题目: 实现数据高效学习：COVID-19 CT 肺和感染分割的基准<br>
DOI: <a href="https://doi.org/10.1002/mp.14676" target="_blank" rel="noopener noreferrer">https://doi.org/10.1002/mp.14676<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br>
Cite: Ma, J., Wang, Y., An, X., et al. (2021). Toward data‐efficient learning: A benchmark for COVID‐19 CT lung and infection segmentation. Medical Physics, 48(3), 1197–1210.</p> <div class="custom-block note"><p class="custom-block-title">相关阅读</p> <p>微信公众号：<a href="https://mp.weixin.qq.com/s?__biz=MzkwMjM0MzA5MA==&amp;mid=2247484147&amp;idx=1&amp;sn=c7af7ffe9f93eccd3e8143afb86956b6&amp;chksm=c0a7b22ef7d03b3897ae4de9fb60f31a41cfcc7f14b4c43882d095cafcec60fb91dab09590f1&amp;token=1341494096&amp;lang=zh_CN#rd" target="_blank" rel="noopener noreferrer">文献阅读：实现数据高效学习：COVID-19 CT 肺和感染分割的基准<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <br> <br></p> <p>站内文章：</p> <ol><li><a href="https://tigerz.online/pages/d38252/" target="_blank" rel="noopener noreferrer">文献阅读 --- nnU-Net：a self-configuring method for deep learning-based biomedical image segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://tigerz.online/pages/1c1b2b/" target="_blank" rel="noopener noreferrer">文献阅读 --- Toward data-efficient learning：A benchmark for COVID-19 CT lung and infection segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://tigerz.online/pages/8633a5/" target="_blank" rel="noopener noreferrer">nnUNet：a self-configuring method for deep learning-based biomedical image segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ol></div> <p><strong>作者介绍：</strong></p> <table><thead><tr><th style="text-align:center;">Xiaoping Yang(杨孝平)</th></tr></thead> <tbody><tr><td style="text-align:center;">南京大学</td></tr> <tr><td style="text-align:center;"><a href="mailto:xpyang@nju.edu.cn">xpyang@nju.edu.cn</a></td></tr></tbody></table> <h2 id="abstract"><a href="#abstract" class="header-anchor">#</a> Abstract</h2> <p><strong>目的：</strong> 在 COVID-19 计算机断层扫描（CT）中准确分割肺部（lung）和感染（infection）对于患者的定量管理起着重要作用。大多数现有研究都基于大型和私有的注释数据集，从单个机构获取这些数据集是不切实际的，特别是当放射科医生正在忙于对抗冠状病毒疾病时。此外，由于不同数据集的开发、不同的训练设置和不同的评估指标，目前很难比较当前 COVID-19 CT 分割方法。<br> <strong>方法：</strong> 为了促进数据高效深度学习方法的发展，在本文中，我们基于 70 个注释的 COVID-19 病例建立了三个肺部和感染分割的基准，其中包含当前活跃的研究领域，例如少样本学习、领域泛化和知识转移。为了在不同分割方法之间进行公平比较，我们还提供了标准的训练、验证和测试划分、评估指标以及相应的代码。<br> <strong>结果：</strong> 基于最先进的网络，我们提供了超过 40 个预训练的基准模型，这些模型不仅可以作为开箱即用的分割工具，还可以为对 COVID-19 肺部和感染分割感兴趣的研究人员节省计算时间。我们分别实现了左肺、右肺和感染的平均 dice 相似系数（DSC）分数为 97.3％、97.7％ 和 67.3％，以及平均标准化表面 dice（NSD）分数为 90.6％、91.4％ 和 70.0％。<br> <strong>结论：</strong> 据我们所知，本研究提供了医学图像分割的第一个数据高效学习基准，以及迄今为止最多的预训练模型。所有这些资源都是公开的，我们的工作为促进用有限数据高效分割 COVID-19 CT 的深度学习方法的发展奠定了基础。</p> <h2 id="_1-introduction"><a href="#_1-introduction" class="header-anchor">#</a> 1. INTRODUCTION</h2> <p>Coronavirus disease 2019（COVID-19）在过去几个月内已经在全球范围内蔓延，并根据世卫组织统计数据，截至 2020 年 11 月 30 日已经导致超过 6100 万人感染。计算机断层扫描（CT）在抗击 COVID-19 方面发挥了重要作用。CT 被证明比逆转录-聚合酶链式反应（RT-PCR）测试更敏感，可以更早地诊断 COVID-19 感染。Wang et al. 对 325 份 COVID-19 CT 扫描和 740 份典型肺炎扫描进行了深度学习模型的训练。他们的模型可以识别出先前被 RT-PCR 测试漏掉的 46 个 COVID-19 病例。此外，CT 图像中的定量信息，如肺负担、高密度比例和肺严重程度评分等，可以用于监测疾病进展并帮助我们了解 COVID-19 的病程。</p> <p>人工智能（AI）方法，特别是基于深度学习的方法，在医学图像分析中广泛应用于抗击 COVID-19。例如，AI 可以用于建立一种非接触式成像工作流程，以防止患者将病毒传染给医护人员。此外，大多数 COVID-19 的筛查和分割算法都是使用深度学习模型开发的，并且自动诊断和 COVID-19 感染量化系统通常依赖于深度神经网络生成的分割结果。</p> <p>尽管有几项研究显示深度学习方法具有在 CT 图像中提供准确和定量评估 COVID-19 感染的潜力，但解决方案主要依赖于大型私有数据集。由于涉及患者隐私和知识产权问题，这些数据集和解决方案可能不会公开发布。然而，研究人员可能希望作者提供数据集、完整的源代码和训练模型。</p> <p>现有的研究表明，如果有数百个标记良好的训练案例可用，经典的 U-Net（or V-Net）可以实现有前途的分割性能。在不同的私人数据集上，各种基于 U-Net 的方法报告了 83.1％ 至 91.6％ 的分割性能，以 Dice 分数系数衡量。 Shan et al. 开发了基于 V-Net 和瓶颈结构的神经网络，用于分割和量化感染区域。在他们的 human-in-the-loop 策略中，他们分别使用了 36、114 和 249 个标记的 CT 扫描，实现了 85.1％、91.0％和 91.6％ 的 dice。Huang et al. 使用 774 个案例的注释数据集，采用 U-Net 进行肺和感染处理，并证明训练好的模型可以用于量化疾病负担和监测疾病进展或治疗反应。总的来说，我们观察到的趋势是，用更多的注释来训练深度学习模型将减少描绘感染所需的时间，并增加分割的准确性，这与 Shan et al. 的发现一致。然而，获取 3D CT 体积数据的注释成本很高，因为这不仅依赖于放射科医师的专业诊断知识，而且需要很多时间和人力，特别是在当前情况下。因此，一个关键的问题是：</p> <p>我们如何在有限的训练数据下自动注释 COVID-19 CT 扫描？</p> <p>关于这个问题，有三个基本但重要的问题没有得到解决：</p> <ul><li>目前并没有公开标记良好的 COVID-19 CT 3D 数据集；数据收集是开发 COVID-19 分割的深度学习方法的第一步和关键步骤。大多数现有研究都依赖于拥有数百个标注 CT 扫描的大型私人数据集。</li> <li>目前没有公开基准来评估不同的基于深度学习的解决方案，不同的研究通常使用各种评估指标。同样，用于训练、验证和测试的数据集被分割得多样化，这也使得读者难以比较这些方法。例如，虽然 MedSeg（<a href="http://medicalsegmentation.com/covid19/" target="_blank" rel="noopener noreferrer">http://medicalsegmentation.com/covid19/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）数据集中有 100 个标注的切片被用于开发 COVID-19 分割方法，但数据集被不同的方式分割，并且开发的方法使用不同的度量标准进行评估。</li> <li>目前没有公开可用的 COVID-19 基准模型。U-Net 是一种著名的分割架构，在许多研究中通常用作基线网络。然而，由于不同的实现，即使在相同的数据集上进行实验，不同的研究也会报告不同的性能。</li></ul> <p>在本文中，我们着重研究注释效率高的深度学习解决方案，旨在通过提供经过良好标记的 COVID-19 CT 数据集和基准来缓解上述问题。具体而言，我们首先提供了一个 COVID-19 3D CT 数据集，其中包含左肺、右肺和感染标注，然后建立了三个基准任务，探索有限训练案例下的不同深度学习策略。最后，我们基于 U-Net 为每个任务建立了综合 baselines。</p> <p>我们的任务针对医学图像领域中的三个流行研究领域：</p> <ul><li>少样本学习（Few-shot learning）：从非常少的样本构建高性能模型。虽然大多数现有方法集中于自然图像，但在医学图像中，生成标签要困难得多。</li> <li>领域泛化（Domain generalization）：从已知领域中学习并应用于具有不同数据分布的未知目标领域。领域泛化的最终目标是训练出对新的未见过领域具有泛化能力的强健模型。最近，模型不可知学习已成为实现这一目标的新兴研究主题。</li> <li>知识迁移（Knowledge transfer）：重复利用现有标注来提高在新数据集或相关新任务上的训练/微调效果。与领域泛化相反，源领域/任务和目标领域/任务均已知，我们重点关注存储和重用从源领域/任务中获得的知识。这项任务在最近的研究中引起了极大关注，如在分割任务中使用迁移学习或生成对抗网络将知识从公开可用的标注数据集转移到新数据集中。</li></ul> <p>肺部和感染分割的大规模数据疗法已经得到了广泛研究。在本文中，我们专注于小数据学习任务，因为这是一个更实际的问题，大规模标注数据集收集起来费时费力。此外，目标是为仅有有限案例时的重要机器学习任务奠定基础。设计新方法不在本文的范围之内。我们的贡献可以总结如下：</p> <ul><li>我们提供了一个新的 COVID-19 CT 数据集，左肺、右肺和感染由胸部放射科医师进行了良好的标注。</li> <li>我们建立了三个基准任务来推进对 COVID-19 CT 扫描分割的数据高效深度学习的研究。具体来说，我们专注于少样本学习、领域泛化和知识迁移，这也是当前研究的热点。据我们所知，这是医学图像分割领域中首个数据高效学习基准测试。</li> <li>我们提供了 40 多个训练好的最先进模型和相应的分割结果，这些结果公开可用，可以作为强有力的基线。更重要的是，这些训练好的模型可以作为 COVID-19 CT 肺部和感染分割的开箱即用工具，可以减少放射科医生的标注时间。</li></ul> <h2 id="_2-materials"><a href="#_2-materials" class="header-anchor">#</a> 2. MATERIALS</h2> <p>COVID-19 CT 扫描的注释很少，但是有几个带有其他疾病的肺部 CT 注释可供公开使用。因此，我们基准测试的主要目标之一是探索使用这些现有注释是否可能帮助 COVID-19 CT 分割。本节介绍了我们分割基准测试中使用的公共数据集。Figure 1 展示了每个数据集的一些示例。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/FIG1.6fenu2zf7ho0.webp" alt="Figure 1"></p> <div class="custom-block note"><p class="custom-block-title">FIG. 1. 五个肺计算机断层扫描（CT）数据集的例子</p> <p>第一和第二行分别表示原始非对比 CT 图像和肺部及病变的相应 ground truth。第三行显示了 ground truth 值的三维渲染结果。MSD Lung Tumor 和 MosMed 数据集（第三列）不提供肺部掩模。红色、绿色和蓝色分别表示左肺、右肺和肺部病变。第三行中的蓝色图例代表不同的肺部病变类型。[Color figure can be viewed at wileyonlinelibrary.com]</p></div> <h3 id="_2-a-现有的肺-ct-分割数据集"><a href="#_2-a-现有的肺-ct-分割数据集" class="header-anchor">#</a> 2.A. 现有的肺 CT 分割数据集</h3> <h4 id="_2-a-1-structseg-肺器官分割"><a href="#_2-a-1-structseg-肺器官分割" class="header-anchor">#</a> 2.A.1. StructSeg 肺器官分割</h4> <p>有 50 份肺癌患者的 CT 扫描可供使用，所有病例均来自同一医疗中心。这个数据集在 2019 年 MICCAI 会议上作为分割挑战任务。其中六个器官得到了注释，包括左肺、右肺、脊髓、食管、心脏和气管。在本文中，我们仅使用左肺和右肺的注释。</p> <h4 id="_2-a-2-nsclc-左右肺分割"><a href="#_2-a-2-nsclc-左右肺分割" class="header-anchor">#</a> 2.A.2. NSCLC 左右肺分割</h4> <p>该数据集包括从肺癌成像归档中 402 个 CT 扫描的左右胸部体积分割。</p> <h3 id="_2-b-现有的肺病变-ct-分割数据集"><a href="#_2-b-现有的肺病变-ct-分割数据集" class="header-anchor">#</a> 2.B. 现有的肺病变 CT 分割数据集</h3> <h4 id="_2-b-1-msd-肺肿瘤分割"><a href="#_2-b-1-msd-肺肿瘤分割" class="header-anchor">#</a> 2.B.1. MSD 肺肿瘤分割</h4> <p>这个数据集包括来自斯坦福大学 (Palo Alto, CA, USA) 的非小细胞肺癌（NSCLC）患者数据，可以通过 TCIA 公开获取。该数据集在 2018 年 MICCAI 会议上作为分割挑战任务。肿瘤由一位专业的胸部放射科医师进行注释，共提供 63 个标注的 CT 扫描。</p> <h4 id="_2-b-2-structseg-肺癌的总靶体积分割"><a href="#_2-b-2-structseg-肺癌的总靶体积分割" class="header-anchor">#</a> 2.B.2. StructSeg 肺癌的总靶体积分割</h4> <p>与上述 StructSeg 肺器官分割数据集相同，提供了相同的 50 份肺癌患者 CT 扫描，并在每个案例中注释了肿瘤的粗略目标体积。</p> <h4 id="_2-b-3-nsclc-胸腔积液-pe-分割"><a href="#_2-b-3-nsclc-胸腔积液-pe-分割" class="header-anchor">#</a> 2.B.3. NSCLC 胸腔积液（PE）分割</h4> <p>该数据集中的 CT 扫描与 NSCLC 左右肺分割数据集中的扫描相同，但针对 78 个案例标注了胸腔积液。</p> <h4 id="_2-b-4-mosmed-dataset"><a href="#_2-b-4-mosmed-dataset" class="header-anchor">#</a> 2.B.4. MosMed dataset</h4> <p>该数据集包含由莫斯科市立医院提供的 50 个 COVID-19 CT 扫描，用于评估深度学习模型的泛化能力，我们在以下基准设置中将其作为独立测试集。</p> <h3 id="_2-c-我们的-covid-19-ct-seg-数据集"><a href="#_2-c-我们的-covid-19-ct-seg-数据集" class="header-anchor">#</a> 2.C. 我们的 COVID-19-CT-Seg 数据集</h3> <p>我们从 Coronacases Initiative 和 Radiopaedia 收集了 20 个公开的 COVID-19 CT 扫描，可在 CC BY-NC-SA 许可下免费下载。所有案例均为 COVID-19 感染。肺部感染的比例在 0.01％ 到 59％ 之间。左肺、右肺和感染区域由具有 1-5 年经验的初级注释者首先勾勒出来，然后由两名具有 5-10 年经验的放射科医师进行精细化，最后所有的注释都由一名具有 10 年以上胸部放射学经验的高级放射科医师进行验证和精细化。整个肺部掩膜包括正常和病理区域。所有的注释都是在轴向图像上逐层手动使用 ITK-SNAP 进行的。平均而言，勾勒一个具有 250 个切片的 CT 扫描需要大约 400 x 45 分钟。总共有 300 多个感染区域，包括 1800 多个切片。我们已经在 <a href="https://zenodo.org/record/3757476" target="_blank" rel="noopener noreferrer">https://zenodo.org/record/3757476<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 上使用 CC BY-NC-SA 许可公开发布了所有的注释。</p> <h2 id="_3-methods"><a href="#_3-methods" class="header-anchor">#</a> 3. METHODS</h2> <p>如第 1 部分所述，需要创新策略以实现 COVID-CT 分割的数据高效方法。因此，我们设置了三个任务来评估潜在的标注高效策略。具体而言，我们关注使用以下内容学习在 COVID-19 CT 扫描中分割左肺、右肺和感染区域：</p> <ul><li>仅使用有限的 COVID-19 CT 扫描进行纯分割；</li> <li>使用其他非 COVID-19 肺部疾病的现有注释肺部 CT 扫描；</li> <li>包括 COVID-19 和非 COVID-19 CT 扫描的异质数据集。</li></ul> <p>此外，我们还提供统一的数据（训练、验证和测试）分割、实验设置和评估指标，以规范基于深度学习的分割协议，从而实现不同研究之间的公正比较。</p> <h3 id="_3-a-task-1-使用有限的注释进行学习"><a href="#_3-a-task-1-使用有限的注释进行学习" class="header-anchor">#</a> 3.A. Task 1: 使用有限的注释进行学习</h3> <p>Task 1 (Table I) 旨在解决少样本学习的问题，即训练数据仅有少量注释。该任务基于 COVID-19-CT-Seg 数据集，包含三个子任务，分别旨在对肺部、感染和两者进行分割。每个子任务报告 fivefold cross-validation
结果（基于预定义的数据集划分文件）。在每个 fold 中，使用 4 个训练样本进行训练，其余 16 个样本用于验证。此外，MosMed 数据集用作独立测试集。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE1.2lo7mgoti6s0.webp" alt="TABLE I"></p> <div class="custom-block note"><p class="custom-block-title">TABLE I. COVID-19 CT 扫描中 Task 1 的肺部和感染分割（有限注释学习）的实验设置。所有实验均基于 COVID-19-CT-Seg 数据集。</p></div> <h3 id="_3-b-task-2-学习将-covid-19-ct-扫描与非-covid-19-ct-扫描进行分割"><a href="#_3-b-task-2-学习将-covid-19-ct-扫描与非-covid-19-ct-扫描进行分割" class="header-anchor">#</a> 3.B. Task 2: 学习将 COVID-19 CT 扫描与非 COVID-19 CT 扫描进行分割</h3> <p>Task 2 (Table II) 旨在解决领域泛化的问题，即仅有非 COVID-19 数据集可用于训练。具体而言，在第一个子任务中，使用 StructSeg Lung 数据集和 NSCLC Lung 数据集进行训练。在第二个子任务中，使用 MSD Lung Tumor、StructSeg Gross Target 和 NSCLC Pleural Effusion 数据集作为训练集。对于这两个子任务，随机选择 80% 的数据进行训练，其余 20% 作为领域内测试集。在两个标注的 COVID-19 CT 数据集中的所有病例均用于测试。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE2.kbpajf9pyhc.webp" alt="TABLE II"></p> <div class="custom-block note"><p class="custom-block-title">TABLE II. Task 2 的实验设置（学习从 non-COVID-19 CT 扫描中分割 COVID-19 CT 扫描）在 COVID-19 CT 扫描中的肺部和感染分割。</p></div> <h3 id="_3-c-task-3-同时学习-covid-19-和-non-covid-19-ct-扫描"><a href="#_3-c-task-3-同时学习-covid-19-和-non-covid-19-ct-扫描" class="header-anchor">#</a> 3.C. Task 3: 同时学习 COVID-19 和 non-COVID-19 CT 扫描</h3> <p>Task 3 (Table III) 旨在解决异构数据集的知识转移问题，即训练集包含领域内和领域外的数据。具体而言，在肺分割和肺感染分割的两个子任务中，使用 80% 的 non-COVID-19 数据和 20% 的 COVID-19 数据进行训练，其余的 20% 和 80% 数据用于验证和测试。此外，MosMed 数据集用作额外的测试集。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE3.54a84lnb6ms0.webp" alt="TABLE III"></p> <div class="custom-block note"><p class="custom-block-title">TABLE III. Task 3（同时使用 COVID-19 和 non-COVID-19 CT 扫描进行学习）在 COVID-19 CT 扫描中进行肺部和感染分割的实验设置。</p></div> <h3 id="_3-d-评价指标"><a href="#_3-d-评价指标" class="header-anchor">#</a> 3.D. 评价指标</h3> <p>受知名医学图像分割十项全能竞赛评估方法的启发，我们还采用了两种互补的指标来评估分割性能。Dice 相似系数（DSC）是一种基于区域的度量方法，用于评估区域重叠度。规范化表面 Dice（NSD）是一种基于边界的度量方法，用于评估在指定容差 τ 下分割结果和 ground truth 表面之间的接近程度。对于这两种指标，得分越高表示分割性能越好，100% 表示完美的分割。设 G、S 分别表示 ground truth 和分割结果，则定义如下：</p> <h4 id="_3-d-1-基于区域的度量"><a href="#_3-d-1-基于区域的度量" class="header-anchor">#</a> 3.D.1. 基于区域的度量</h4> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/3.D.1.4h8gwm363uo0.webp" alt="3.D.1"></p> <h3 id="_3-d-2-基于边界的测量"><a href="#_3-d-2-基于边界的测量" class="header-anchor">#</a> 3.D.2. 基于边界的测量</h3> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/3.D.2.6zazk3lpvcw0.webp" alt="3.D.2"></p> <h3 id="_3-e-u-net-baselines-oldies-but-goldies"><a href="#_3-e-u-net-baselines-oldies-but-goldies" class="header-anchor">#</a> 3.E. U-Net baselines: Oldies but goldies</h3> <p>U-Net 是在 5 年前提出的，许多变体已被提出以改进它。然而，最近的研究表明，如果相应的流程被充分设计，那么很难超越基本的 U-Net。特别是，nnU-Net（no-new-U-Net）被提出来自动适应给定的 3D 医学数据集的预处理策略和网络架构（即池化次数、卷积核大小和步长大小）。没有手动调整，nnU-Net 可以在 19 个公开的国际分割竞赛中取得比大多数专门的深度学习流程更好的性能，并在大多数 49 个任务中创下新的最佳表现。源代码可在 <a href="https://github.com/MIC-DKFZ/nnUNet" target="_blank" rel="noopener noreferrer">https://github.com/MIC-DKFZ/nnUNet<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 上公开获取。</p> <p>在现有的 COVID-19 CT 分割研究中，U-Net 通常被用作基准模型。然而，即使在同一数据集中，报告的结果也存在很大的差异，这使得比较不同的研究变得困难。为了标准化 U-Net 的性能，我们基于 nnU-Net 构建基准，据我们所知，这是目前最强大的 U-Net 实现。为了使不同任务可比较，我们手动调整了 Task 2 和Task 3 的补丁大小和网络架构，使其与 Task 1 相同。Figure 2 显示了 U-Net 的细节架构。</p> <p>在预处理期间，我们使用 Z-Score（均值减法和标准差除法）对图像强度进行标准化。在训练期间，我们使用nnU-Net 的标准训练方案。例如，我们使用交叉熵和 Dice 损失之间的和作为损失函数。优化器为随机梯度下降，具有初始学习率（0.01）和较大的 Nesterov 动量（0.99），并使用“PolyLR”调度方法来降低学习率。我们随机采样大小为 192×192×64 的图像块。所有的训练过程都运行了 1000 个固定长度的 epoch，其中每个 epoch 定义为 250 个训练迭代（batch size 2）。在测试期间，我们使用相同大小的滑动窗口的图像块来推断测试样例，滑动步长为块大小的一半。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/FIG2.2x8t9mcxoeg0.webp" alt="Figure 2"></p> <div class="custom-block note"><p class="custom-block-title">FIG. 2. 在本工作中使用的 3D U-Net 体系结构的细节</p> <p>卷积块附近的数字（例如，32×56×160×92）表示每个分辨率中的特征图大小，白色矩形中的数字（例如，1、2、2）表示卷积核的步幅大小。[Color figure can be viewed at wileyonlinelibrary.com]</p></div> <h2 id="_4-results-and-discussion"><a href="#_4-results-and-discussion" class="header-anchor">#</a> 4. RESULTS AND DISCUSSION</h2> <p>本节介绍每个任务的定量分割结果。为了清晰起见，前三个小节显示了每个任务的验证集和第一个测试集上的分割结果。我们总结了第二个测试集（MosMed数据集）上的所有分割结果，并在最后一个小节中比较了三个任务的结果。</p> <h3 id="_4-a-results-of-task-1-使用有限的注释进行学习"><a href="#_4-a-results-of-task-1-使用有限的注释进行学习" class="header-anchor">#</a> 4.A. Results of task 1: 使用有限的注释进行学习</h3> <p>Table IV 展示了 Task 1 中各子任务肺部和感染的平均 DSC 和 NSD 结果。可以发现：</p> <ul><li>不同 folds 的平均 DSC 和 NSD 值差异很大。这是因为每个 fold 的测试样本难度不同，这表明报告 fivefold cross-validation 结果是必要的，以获得客观评估，而 onefold 结果可能存在偏差。</li> <li>在 COVID-19 CT 扫描中，仅使用四个训练样本就可以取得很好的左肺和右肺分割结果。相比于同时训练肺和感染分割模型，只训练肺分割模型可以获得更好的结果。</li> <li>对于有限的注释，感染分割仍有很大的提升空间。</li></ul> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE4.690uhv085ec0.webp" alt="TABLE IV"></p> <div class="custom-block note"><p class="custom-block-title">TABLE IV. 对 Task 1 的 COVID-19-CT-Seg 数据集的 fivefold cross validation 的定量结果：使用有限的注释进行学习。对于每个 fold，报告平均 DSC 和 NSD 值。最后一行显示了 80 个（=5 folds × 16 testing cases per fold）测试用例的平均结果。</p></div> <p>Figure 3 展示了 Task 1 中一些可视化的分割结果。可以发现，分开训练的方式可以获得更好的结果，特别是对于左肺和右肺分割。联合训练会混淆左右肺，从而对感染分割产生不利影响。这是因为多任务分割比单任务更难，特别是当每个单独的任务都很具有挑战性时。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/FIG3.3ipuqmg5jq40.webp" alt="Figure 3"></p> <div class="custom-block note"><p class="custom-block-title">FIG. 3. Task 1 中分割结果的可视化示例</p> <p>Task1-Separate 是指训练分离的网络进行肺和感染分割的结果。Task1-Union 是指训练一个单一的模型的肺和感染分割。红、绿、蓝分别表示左肺、右肺和感染情况。[Color figure can be viewed at wileyonlinelibrary.com]</p></div> <h3 id="_4-b-results-of-task-2-学习将-covid-19-ct-扫描与-non-covid-19-ct-扫描分割"><a href="#_4-b-results-of-task-2-学习将-covid-19-ct-扫描与-non-covid-19-ct-扫描分割" class="header-anchor">#</a> 4.B. Results of task 2: 学习将 COVID- 19 CT 扫描与 non-COVID-19 CT 扫描分割</h3> <p>本任务非常具有挑战性，因为模型在训练期间不会看到目标域中的任何情况。换句话说，训练的模型应该推广到未见过的域（COVID-19 CT）。Table V 显示了左肺和右肺分割结果的平均值和标准差，以 DSC 和 NSD 为指标。可以发现：</p> <ul><li>3D U-Net 在域内集上的 DSC 表现非常出色。平均 NSD 值低于 DSC 值，这意味着大部分错误来自于边界。</li> <li>在两个子任务上，测试集的性能都显著下降。在 NSCLC Lung 数据集上训练的模型的性能比在 StuctSeg lung 数据集上训练的模型差。这可能的原因是 StructSeg 和 COVID-19-CT 之间的肺外观分布差异较小。</li></ul> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE5.3zpbcolz28q0.webp" alt="TABLE V"></p> <div class="custom-block note"><p class="custom-block-title">TABLE V. Task 2 中肺分割的定量结果（平均±标准差）。粗体的数字是最好的结果。</p></div> <p>Table VI 以 DSC 和 NSD 的平均值和标准差为指标，展示了感染分割的定量结果。可以发现：</p> <ul><li>在域内测试集上，病变分割的性能不如肺分割的性能（Table V），这意味着肿瘤分割仍然是一个具有挑战性的问题。这一观察结果符合最近在 MICCAI 肿瘤分割挑战中的结果，即肝脏肿瘤分割和肾脏肿瘤分割。</li> <li>模型几乎无法在测试集上预测 COVID-19 感染，这突出了 CT 扫描中肺癌、胸腔积液和 COVID-19 感染之间的病变外观差异显著。</li></ul> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE6.51bze42sq880.webp" alt="TABLE VI"></p> <div class="custom-block note"><p class="custom-block-title">TABLE VI. Task 2 中感染分割的定量结果（平均±标准差）。粗体的数字是最好的结果。</p></div> <h3 id="_4-c-results-of-task-3-同时学习-covid-19-和-non-covid-19ct-扫描"><a href="#_4-c-results-of-task-3-同时学习-covid-19-和-non-covid-19ct-扫描" class="header-anchor">#</a> 4.C. Results of task 3: 同时学习 COVID-19 和 non-COVID-19CT 扫描</h3> <p>在 Task 3 中，利用来自 COVID-19 和 non-COVID-19 数据集的异构案例来训练模型，以对 COVID-19 CT 扫描中的肺和感染进行分割。由于多个领域之间存在差距，这种数据融合有望探索融合不同注释如何影响模型在每个单独数据集上的性能。</p> <p>Table VII 呈现了左肺和右肺分割的定量 fivefold cross-validation 结果，平均 DSC 和 NSD 值。可以发现：</p> <ul><li>在验证集上，平均 DSC 和 NSD 值与 Task 2 的结果基本一致，在左肺分割中实现了高达 96.4% 的DSC，在右肺分割中实现了 97.2% 的 DSC。</li> <li>然而，在测试集上，平均 DSC 和 NSD 值略微下降，表明尽管在 CT 扫描上分割相同的肺器官，non-COVID-19 和 COVID-19 CT 数据集之间仍然存在一些领域差距。</li></ul> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE7.3fdmnlvuels0.webp" alt="TABLE VII"></p> <div class="custom-block note"><p class="custom-block-title">TABLE VII. Task 3 中左肺和右肺分割的 fivefold cross validation 的定量结果。粗体的数字是最好的结果。</p></div> <p>Table VIII 呈现了 fivefold cross validation 的感染分割的定量结果，可以发现：</p> <ul><li>即使使用了大量的来自 non-COVID-19 数据集的肺部病变注释，fivefold cross validation 结果之间的差异是明显的。因此，在这个任务中报告 fivefold cross validation 的结果对于可靠和稳健的评估是必要的。</li> <li>与 Task 2 中的结果相比（Table VI），包括四个 COVID-19 病例在内的训练集带来了显著的改进，对于 StructSeg 肺肿瘤分割，DSC 提高了 7.5%，NSCLC 胸腔积液分割 DSC 提高了 1.1%，而 MSD 肺肿瘤分割的性能下降了 3.3%。这些结果表明，在训练集中包含少量的越界病例可能会显著改变模型的性能。</li> <li>在测试集上，相对性能下降了约 4%-14% 的 DSC 和 11%-16% 的 NSD，表明仅仅融合 COVID-19 和 non-COVID-19 案例对于在 COVID-19 CT 扫描中分割感染仍然是低效的。因此，仍有很大的改进空间，通过先进的知识转移技术来弥合许多 non-COVID-19 肺部病变案例和有限的 COVID-19 案例之间的差距。</li></ul> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE8.5xvltrfxyyg0.webp" alt="TABLE VIII"></p> <div class="custom-block note"><p class="custom-block-title">TABLE VIII. Task 3 中左肺和右肺分割的 fivefold cross validation 的定量结果。粗体的数字是最好的结果。</p></div> <h3 id="_4-d-不同任务之间的比较"><a href="#_4-d-不同任务之间的比较" class="header-anchor">#</a> 4.D. 不同任务之间的比较</h3> <p>Tasks 1-3 对应于在 COVID-19 CT 扫描中使用有限的域内训练案例和域外数据集进行肺部和感染分割的不同策略。Tasks 1-3 的测试案例相同，因此在不同任务之间进行比较是可行和合理的。Table IX 以平均 DSC 和 NSD 的形式呈现了三个任务所有测试集的定量结果。Task 1-Separate 和 -Union 分别表示训练网络以分别和同时分割肺部和感染。Figure 4 显示了关于 DSC 和 NSD 的 COVID-19-CT-Seg 数据集中所有任务的左肺，右肺和感染分割结果的小提琴图。小提琴图不仅显示了摘要统计信息，如中位数和四分位数范围，还显示了定量结果的整个分布。</p> <p>对于肺部分割，</p> <ul><li>Task 3 实现了最佳表现，达到左肺分割的 97.3％ DSC 和 90.6％ NSD 以及右肺分割的 97.7％ DSC 和 91.4％ NSD。</li> <li>在 Task 1 和 Task 2 的结果比较中，StructSeg 在未见的测试集上取得了明显更好的表现，表明 StructSeg 和 COVID-19 CT 之间的肺部域差距较小。在具有 300 多个训练案例的 NSCLC 数据集上的结果比 COVID-19 数据集上的结果更差，表明训练案例数量并不是最重要的，而在学习过程中包含域内数据则更加重要。</li> <li>在 Task 1 和 Task 3 的结果比较中，添加域外数据集（StructSeg 和 NSCLC）可以提高左右肺分割的性能。结果表明，现有的 non-COVID CT 注释可用于协助 COVID-19 CT 扫描中的肺部分割。这一发现对于快速开发具有有限数据的 COVID-19 肺部分割系统尤为鼓舞，特别是目前 COVID-19 CT 注释很少的情况下。</li> <li>在 Task 2 和 Task 3 的结果比较中，将 COVID-19 案例加入训练集可以在两个子任务（StructSeg 和 NSCLC）上获得性能增益，特别是对于 NSCLC，左肺分割的 DSC 可以显著增加高达 34％。这个结果强调了在训练集中包含少量 COVID-19 案例对于肺部分割至关重要。</li></ul> <p>对于感染区域分割，</p> <ul><li>Task 1 在两个测试集中都达到了最佳表现，分别达到了 DSC 的 67.3％ 和 NSD 的 70.0％。</li> <li>通过比较 Task 1 和 Task 2 的结果，使用四个 COVID-19 CT 训练样例获得的结果显著优于使用其他肺部病变样例（即肺癌和胸腔积液），这突显了在开发 COVID-19 感染分割系统时领域内数据的重要性。</li> <li>通过比较 Task 1 和 Task 3 的结果，在训练期间添加许多（40-62）non-COVID-19 病例会降低而不是提高性能，这意味着领域外的肺部病变数据可能会影响模型对 COVID-19 感染分割的表示能力。</li> <li>通过比较 Task 2 和 Task 3 的结果，仅使用领域外案例无法预测 COVID-19 感染，而添加一些 COVID-19 案例可以显著提高性能，这突显出在训练期间包括一些领域内案例对于开发感染分割模型非常关键。</li></ul> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE9.64aem2sb3sw0.webp" alt="TABLE IX"></p> <div class="custom-block note"><p class="custom-block-title">TABLE IX. COVID-19 CT 肺和感染分割结果对所有检测病例的平均 DSC 和 NSD 值的定量比较。粗体的数字是最好的结果。</p></div> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/FIG4.11yegem9ua5s.webp" alt="Figure 4"></p> <div class="custom-block note"><p class="custom-block-title">FIG. 4. 小提琴图展示了在 COVID-19-CT-Seg 测试集上，不同方法对左肺、右肺和感染分割的表现（DSC 或 NSD）。[Color figure can be viewed at wileyonlinelibrary.com]</p></div> <p>此外，在所有实验中，感染分割性能低于肺部分割有两个主要原因。首先，任务设置是少样本学习，只允许使用有限标记的案例来训练网络。其次，与肺部相比，感染区域相对较小，大多数感染边界较弱。因此，感染分割比肺部分割更具挑战性。Table X 显示了不同任务的分割结果的召回率和精确度。可以发现，感染分割结果具有相对较高的精确度分数和低的召回率分数，表明模型在检测所有感染方面失败更多。肺部分割结果实现了更好的召回率和精确度分数，因为肺组织具有更清晰的边界和更大的尺寸。Figure 5 展示了不同任务的一些可视化分割结果。我们可以发现，肺部分割大多数失败是因为左肺和右肺之间的混淆，因为它们具有非常相似的外观。大且明显的感染具有更好的分割结果。然而，小尺寸或边界较弱的感染往往是最常见的失败案例。</p> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/TABLE10.s2uj1mmeuhs.webp" alt="TABLE X"></p> <div class="custom-block note"><p class="custom-block-title">TABLE X. 定量比较 COVID-19 CT 肺和不同任务的感染分割结果，所有检测病例的平均敏感性和特异性值。</p></div> <p><img src="https://ZhengTiger.github.io/picx-images-hosting/02-%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB-04-%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/20210206_COVID19/FIG5.690gbf9cx3k0.webp" alt="Figure 5"></p> <div class="custom-block note"><p class="custom-block-title">FIG. 5. 在不同的任务中分割结果的可视化例子。红色、绿、蓝色分别表示左肺、右肺和感染情况。 [Color figure can be viewed at wileyonlinelibrary.com]</p></div> <p>总之，使用 non-COVID-19 胸部 CT 数据集可以直接显着改善肺部分割结果，但对感染分割的积极影响很少，因为存在很大的领域差距。我们发现，具有良好对比度和清晰边界的感染即使只有四个训练案例也可以很好地分割。然而，训练好的模型通常会错过小型感染和弱边界感染，表明模型在学习过程中很难捕捉这些特征。我们的结果还突显了需要有效的有限注释数据学习方法。虽然包含更多的训练案例可能是提高感染分割性能的简单直接方法，但应记住，在临床实践中，对于每个医疗中心手动注释许多 3D COVID-19 CT 扫描是不切实际的，特别是当放射科医生忙于抗击流行病时。这是我们建立数据效率学习基准的主要动机。</p> <p>有一些潜在的解决方案可用于提高性能。例如，在少样本学习任务（Task 1）中，可以使用更高级的数据增强方法来增加训练集。此外，设计任务特定的数据增强方法也是一种有前途的解决方案，例如增加更多具有小型和弱边界感染的案例。在领域泛化任务（Task 2）中，仅使用 non-COVID-19 数据集训练的模型无法分割感染。可以引入更先进的模型无关学习方法来处理领域差距，例如元学习。在知识转移任务（Task 3）中，简单地将 non-COVID-19 和 COVID-19 数据集与 SOTA 网络融合可能会使模型更倾向于学习 non-COVID-19 特征。可以使用更强大和稳健的领域适应方法来处理异构数据集，例如自监督学习，跨领域适应。</p> <h3 id="_4-e-limitation"><a href="#_4-e-limitation" class="header-anchor">#</a> 4.E. Limitation</h3> <p>可能存在的一个限制是我们数据集中的病例数相对较少。然而，本文的重点在于如何从有限的训练案例中进行学习。因此，我们认为训练案例的数量对于我们的基准任务是可接受的。更重要的是，这个基准测试也适用于一般的小样本学习问题。此外，第一个测试集（COVID-19-CT-Seg）的病例数量（16或20个）和第二个测试集（MosMed）的病例数量（50个）与最近的 MICCAI 2020 分割挑战相当。例如，StructSeg（放射治疗计划自动结构分割挑战 2020）有 10 个测试案例，而 ASOCA（自动冠状动脉分割）有 20 个测试案例。另一个限制是创新方法的贡献有限。然而，这不是本文的主要目标。相反，我们的主要目标是为学习有限注释数据的未来工作奠定基础，我们认为在该基准测试中提到的数据集和任务可以引起该领域的关注。</p> <h2 id="_5-conclusion"><a href="#_5-conclusion" class="header-anchor">#</a> 5. CONCLUSION</h2> <p>随着 COVID-19 在全球爆发，开发基于深度学习的 COVID-19 图像分析工具已成为紧急需求。为了推动朝着这个目标的研究，本文创建了一个 COVID-19 CT 数据集，建立了三个分割基准任务，并提供了基于最先进的分割架构的 40 多个基线模型。所有相关结果都可以在 <a href="https://github.com/JunMa11/COVID-19-CT-Seg-Benchmark" target="_blank" rel="noopener noreferrer">https://github.com/JunMa11/COVID-19-CT-Seg-Benchmark<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 上公开获取。统一的任务设置可以使研究之间的比较更加可行。公共基线可以为研究人员节省模型训练时间，使他们可以专注于开发自己的方法。我们希望这项工作能加速 COVID-19 有限数据学习的研究。</p></div></div>  <div class="page-edit"><!----> <div class="tags"><a href="/tags/?tag=%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6" title="标签">#生物信息学</a></div> <div class="last-updated"><span class="prefix">更新时间:</span> <span class="time">2024/09/02, 20:17:14</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/1f53c5/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">文献阅读 --- FAN-C:a feature-rich framework for the analysis and visualisation of chromosome conformation capture data</div></a> <a href="/pages/2737d2/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">文献阅读 --- Inference and analysis of cell-cell communication using CellChat</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/1f53c5/" class="prev">文献阅读 --- FAN-C:a feature-rich framework for the analysis and visualisation of chromosome conformation capture data</a></span> <span class="next"><a href="/pages/2737d2/">文献阅读 --- Inference and analysis of cell-cell communication using CellChat</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/9912cc/"><div>
            文献阅读 --- Cell2location maps fine-grained cell types in spatial transcriptomics
            <!----></div></a> <span class="date">08-30</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/e020de/"><div>
            文献阅读 --- An interactive framework for whole-brain maps at cellular resolution
            <!----></div></a> <span class="date">08-30</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/521e00/"><div>
            文献阅读 --- Uncovering the genetic blueprint of the C. elegans nervous system
            <!----></div></a> <span class="date">08-30</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1308155474@qq.com" title="邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/zhenghu159" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://open.weixin.qq.com/qr/code?username=gh_55ff0104c230" title="微信" target="_blank" class="iconfont icon-weixin"></a><a href="https://www.zhihu.com/people/shu-ru-yong-hu-ming-65-69" title="知乎" target="_blank" class="iconfont icon-zhihu"></a><a href="https://www.jianshu.com/u/6dacd977dea9" title="简书" target="_blank" class="iconfont icon-jianshu"></a><a href="https://www.cnblogs.com/tigerzheng/" title="博客园" target="_blank" class="iconfont icon-bokeyuan"></a><a href="https://blog.csdn.net/weixin_45851732" title="CSDN" target="_blank" class="iconfont icon-csdn"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2024
    <span>TigerZ  | Blog<br> <a href="http://beian.miit.gov.cn/" target="_blank"></a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div><div></div><div></div><div id="tcomment"></div><!----><canvas id="vuepress-canvas-cursor"></canvas><div></div></div></div>
    <script src="/assets/js/app.135a3dc6.js" defer></script><script src="/assets/js/2.b95133a4.js" defer></script><script src="/assets/js/125.ffbca55f.js" defer></script><script src="/assets/js/14.330b018e.js" defer></script><script src="/assets/js/4.17f28c7e.js" defer></script><script src="/assets/js/8.113240f8.js" defer></script><script src="/assets/js/11.6804d4e2.js" defer></script>
  </body>
</html>
