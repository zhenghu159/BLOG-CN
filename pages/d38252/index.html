<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>文献阅读 --- nnU-Net：a self-configuring method for deep learning-based biomedical image segmentation | TigerZ Blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="shortcut icon" href="/img/favicon.ico">
    <link rel="stylesheet" href="//at.alicdn.com/t/font_3114978_qe0b39no76.css">
    <noscript><meta http-equiv="refresh" content="0; url=https://www.youngkbt.cn/noscript/"><style>.theme-vdoing-content { display:none }</noscript>
    <script src="https://cdn.staticfile.org/twikoo/1.6.7/twikoo.all.min.js"></script>
    <script>var _hmt = _hmt || [];
          (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?267c5680c2ffb468ca29c45ffe6801da"; 
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
          })();
          </script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    <meta name="description" content="TigerZ个人博客, VuePress搭建, 使用了 Vdoing 主题。">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="keywords" content="TigerZ个人博客, VuePress搭建。">
    <meta name="theme-color" content="#11a8cd">
    <meta name="baidu-site-verification" content="codeva-nuy0c96SLu">
    
    <link rel="preload" href="/assets/css/0.styles.d72a9179.css" as="style"><link rel="preload" href="/assets/js/app.135a3dc6.js" as="script"><link rel="preload" href="/assets/js/2.b95133a4.js" as="script"><link rel="preload" href="/assets/js/121.9d3d53fd.js" as="script"><link rel="preload" href="/assets/js/14.330b018e.js" as="script"><link rel="preload" href="/assets/js/4.17f28c7e.js" as="script"><link rel="preload" href="/assets/js/8.113240f8.js" as="script"><link rel="preload" href="/assets/js/11.6804d4e2.js" as="script"><link rel="prefetch" href="/assets/js/10.3a38bc3c.js"><link rel="prefetch" href="/assets/js/100.07ad7c69.js"><link rel="prefetch" href="/assets/js/101.cf0e9c52.js"><link rel="prefetch" href="/assets/js/102.b677846a.js"><link rel="prefetch" href="/assets/js/103.d978cd23.js"><link rel="prefetch" href="/assets/js/104.aaca6a9e.js"><link rel="prefetch" href="/assets/js/105.b70bc017.js"><link rel="prefetch" href="/assets/js/106.6357bc2a.js"><link rel="prefetch" href="/assets/js/107.52ba7c90.js"><link rel="prefetch" href="/assets/js/108.9bdac9ca.js"><link rel="prefetch" href="/assets/js/109.0424b457.js"><link rel="prefetch" href="/assets/js/110.5e8624f2.js"><link rel="prefetch" href="/assets/js/111.9f280b10.js"><link rel="prefetch" href="/assets/js/112.e3e184c2.js"><link rel="prefetch" href="/assets/js/113.9dc61991.js"><link rel="prefetch" href="/assets/js/114.6a888a2a.js"><link rel="prefetch" href="/assets/js/115.0c868c7e.js"><link rel="prefetch" href="/assets/js/116.5f982486.js"><link rel="prefetch" href="/assets/js/117.05d64b6c.js"><link rel="prefetch" href="/assets/js/118.de1820da.js"><link rel="prefetch" href="/assets/js/119.9e48d583.js"><link rel="prefetch" href="/assets/js/12.5dfbdbbd.js"><link rel="prefetch" href="/assets/js/120.e79c6680.js"><link rel="prefetch" href="/assets/js/122.7704c3e0.js"><link rel="prefetch" href="/assets/js/123.1d7bd3ac.js"><link rel="prefetch" href="/assets/js/124.66f0d159.js"><link rel="prefetch" href="/assets/js/125.ffbca55f.js"><link rel="prefetch" href="/assets/js/126.faa2bafe.js"><link rel="prefetch" href="/assets/js/127.4cd6096d.js"><link rel="prefetch" href="/assets/js/128.c063ce35.js"><link rel="prefetch" href="/assets/js/129.6ff200b7.js"><link rel="prefetch" href="/assets/js/13.0fa098c9.js"><link rel="prefetch" href="/assets/js/130.bd3a34a0.js"><link rel="prefetch" href="/assets/js/131.b1d386f6.js"><link rel="prefetch" href="/assets/js/132.f2e1f89a.js"><link rel="prefetch" href="/assets/js/133.0dd4a6e4.js"><link rel="prefetch" href="/assets/js/134.03528a2c.js"><link rel="prefetch" href="/assets/js/135.5f50f01f.js"><link rel="prefetch" href="/assets/js/136.6038686c.js"><link rel="prefetch" href="/assets/js/137.c3668c24.js"><link rel="prefetch" href="/assets/js/138.52048225.js"><link rel="prefetch" href="/assets/js/139.8a83e4a5.js"><link rel="prefetch" href="/assets/js/140.0c9bf078.js"><link rel="prefetch" href="/assets/js/141.bd662f0c.js"><link rel="prefetch" href="/assets/js/142.03c93ff2.js"><link rel="prefetch" href="/assets/js/143.d81dbfa4.js"><link rel="prefetch" href="/assets/js/144.e2baf63f.js"><link rel="prefetch" href="/assets/js/145.bbc19ffd.js"><link rel="prefetch" href="/assets/js/146.c8bad20d.js"><link rel="prefetch" href="/assets/js/147.76385b63.js"><link rel="prefetch" href="/assets/js/148.0f773ba8.js"><link rel="prefetch" href="/assets/js/149.06f2933d.js"><link rel="prefetch" href="/assets/js/15.b8bb4a86.js"><link rel="prefetch" href="/assets/js/150.80df8c58.js"><link rel="prefetch" href="/assets/js/151.3d18fd70.js"><link rel="prefetch" href="/assets/js/152.2e71a772.js"><link rel="prefetch" href="/assets/js/153.0b4b3e96.js"><link rel="prefetch" href="/assets/js/154.10e02163.js"><link rel="prefetch" href="/assets/js/155.7c69bdf4.js"><link rel="prefetch" href="/assets/js/156.660f1ea4.js"><link rel="prefetch" href="/assets/js/157.b0c3c63c.js"><link rel="prefetch" href="/assets/js/158.2d79cfc7.js"><link rel="prefetch" href="/assets/js/159.839ca4dd.js"><link rel="prefetch" href="/assets/js/16.781d3ca8.js"><link rel="prefetch" href="/assets/js/160.4c0aa430.js"><link rel="prefetch" href="/assets/js/161.26031b01.js"><link rel="prefetch" href="/assets/js/162.7382ebc3.js"><link rel="prefetch" href="/assets/js/163.1b782d65.js"><link rel="prefetch" href="/assets/js/164.29f66df7.js"><link rel="prefetch" href="/assets/js/165.aefb0b28.js"><link rel="prefetch" href="/assets/js/166.5a1e69d1.js"><link rel="prefetch" href="/assets/js/167.9ec8f2b4.js"><link rel="prefetch" href="/assets/js/168.8e72cb0f.js"><link rel="prefetch" href="/assets/js/169.00457935.js"><link rel="prefetch" href="/assets/js/17.14bdc8cc.js"><link rel="prefetch" href="/assets/js/170.02889291.js"><link rel="prefetch" href="/assets/js/171.18d34ca2.js"><link rel="prefetch" href="/assets/js/172.9eead420.js"><link rel="prefetch" href="/assets/js/173.526e718c.js"><link rel="prefetch" href="/assets/js/174.7b94dd0c.js"><link rel="prefetch" href="/assets/js/175.b34180db.js"><link rel="prefetch" href="/assets/js/176.df484597.js"><link rel="prefetch" href="/assets/js/177.bd35bd12.js"><link rel="prefetch" href="/assets/js/178.c0a11a10.js"><link rel="prefetch" href="/assets/js/179.e31946e2.js"><link rel="prefetch" href="/assets/js/18.14ae8e93.js"><link rel="prefetch" href="/assets/js/180.764682cc.js"><link rel="prefetch" href="/assets/js/181.977f1390.js"><link rel="prefetch" href="/assets/js/182.2692f937.js"><link rel="prefetch" href="/assets/js/183.e8af2276.js"><link rel="prefetch" href="/assets/js/184.b4e1ac36.js"><link rel="prefetch" href="/assets/js/185.6e4ecc97.js"><link rel="prefetch" href="/assets/js/186.989245c1.js"><link rel="prefetch" href="/assets/js/187.80231977.js"><link rel="prefetch" href="/assets/js/188.d083d8df.js"><link rel="prefetch" href="/assets/js/189.26567c30.js"><link rel="prefetch" href="/assets/js/19.bb80f057.js"><link rel="prefetch" href="/assets/js/190.3873532c.js"><link rel="prefetch" href="/assets/js/191.05e3fbd2.js"><link rel="prefetch" href="/assets/js/192.4b8ea243.js"><link rel="prefetch" href="/assets/js/193.28a8daba.js"><link rel="prefetch" href="/assets/js/194.d573e176.js"><link rel="prefetch" href="/assets/js/195.8f7be313.js"><link rel="prefetch" href="/assets/js/196.e671f76e.js"><link rel="prefetch" href="/assets/js/197.fd0b0e77.js"><link rel="prefetch" href="/assets/js/198.9d6d57a8.js"><link rel="prefetch" href="/assets/js/199.b01e4408.js"><link rel="prefetch" href="/assets/js/20.04e82b51.js"><link rel="prefetch" href="/assets/js/200.41fbcbdb.js"><link rel="prefetch" href="/assets/js/201.112b825c.js"><link rel="prefetch" href="/assets/js/202.78dabbb8.js"><link rel="prefetch" href="/assets/js/203.d712629e.js"><link rel="prefetch" href="/assets/js/204.3244b025.js"><link rel="prefetch" href="/assets/js/205.20d2a208.js"><link rel="prefetch" href="/assets/js/21.2bb87dd4.js"><link rel="prefetch" href="/assets/js/22.9f6217ab.js"><link rel="prefetch" href="/assets/js/23.5e274244.js"><link rel="prefetch" href="/assets/js/24.b9574f9e.js"><link rel="prefetch" href="/assets/js/25.137ded62.js"><link rel="prefetch" href="/assets/js/26.875ef211.js"><link rel="prefetch" href="/assets/js/27.21478680.js"><link rel="prefetch" href="/assets/js/28.a17d8c74.js"><link rel="prefetch" href="/assets/js/29.82ee0284.js"><link rel="prefetch" href="/assets/js/3.3abf1aa3.js"><link rel="prefetch" href="/assets/js/30.f0a41074.js"><link rel="prefetch" href="/assets/js/31.67a239e0.js"><link rel="prefetch" href="/assets/js/32.2a07296f.js"><link rel="prefetch" href="/assets/js/33.3c91d254.js"><link rel="prefetch" href="/assets/js/34.fedaa0c2.js"><link rel="prefetch" href="/assets/js/35.b2bf202a.js"><link rel="prefetch" href="/assets/js/36.ba0c39cd.js"><link rel="prefetch" href="/assets/js/37.6c5d6dea.js"><link rel="prefetch" href="/assets/js/38.6898e0d0.js"><link rel="prefetch" href="/assets/js/39.51032bd3.js"><link rel="prefetch" href="/assets/js/40.54330115.js"><link rel="prefetch" href="/assets/js/41.0e5fc4df.js"><link rel="prefetch" href="/assets/js/42.b8579e68.js"><link rel="prefetch" href="/assets/js/43.f0d87263.js"><link rel="prefetch" href="/assets/js/44.dadf352d.js"><link rel="prefetch" href="/assets/js/45.48126a39.js"><link rel="prefetch" href="/assets/js/46.daffcf96.js"><link rel="prefetch" href="/assets/js/47.910b1864.js"><link rel="prefetch" href="/assets/js/48.ef8b1d7c.js"><link rel="prefetch" href="/assets/js/49.627389f0.js"><link rel="prefetch" href="/assets/js/5.ff06ff0e.js"><link rel="prefetch" href="/assets/js/50.a8db01db.js"><link rel="prefetch" href="/assets/js/51.7ee63ade.js"><link rel="prefetch" href="/assets/js/52.704a676f.js"><link rel="prefetch" href="/assets/js/53.885a2d7c.js"><link rel="prefetch" href="/assets/js/54.15136c57.js"><link rel="prefetch" href="/assets/js/55.86145f9f.js"><link rel="prefetch" href="/assets/js/56.619fcbc5.js"><link rel="prefetch" href="/assets/js/57.d5ab5e8b.js"><link rel="prefetch" href="/assets/js/58.ed36b9cb.js"><link rel="prefetch" href="/assets/js/59.a6d66110.js"><link rel="prefetch" href="/assets/js/6.78d855d4.js"><link rel="prefetch" href="/assets/js/60.80777eb6.js"><link rel="prefetch" href="/assets/js/61.e0ad0e0b.js"><link rel="prefetch" href="/assets/js/62.170fe53a.js"><link rel="prefetch" href="/assets/js/63.987c67c8.js"><link rel="prefetch" href="/assets/js/64.d110743c.js"><link rel="prefetch" href="/assets/js/65.b891a616.js"><link rel="prefetch" href="/assets/js/66.f0afa649.js"><link rel="prefetch" href="/assets/js/67.a2999e6f.js"><link rel="prefetch" href="/assets/js/68.4304a9a3.js"><link rel="prefetch" href="/assets/js/69.ca4ccc73.js"><link rel="prefetch" href="/assets/js/7.ca82cfad.js"><link rel="prefetch" href="/assets/js/70.82988a8d.js"><link rel="prefetch" href="/assets/js/71.c647d9ae.js"><link rel="prefetch" href="/assets/js/72.1a7bd048.js"><link rel="prefetch" href="/assets/js/73.d0d8f205.js"><link rel="prefetch" href="/assets/js/74.2487173f.js"><link rel="prefetch" href="/assets/js/75.96c44e6a.js"><link rel="prefetch" href="/assets/js/76.97334731.js"><link rel="prefetch" href="/assets/js/77.0f523633.js"><link rel="prefetch" href="/assets/js/78.a2b1b565.js"><link rel="prefetch" href="/assets/js/79.bc117446.js"><link rel="prefetch" href="/assets/js/80.e9de3364.js"><link rel="prefetch" href="/assets/js/81.de3e1a8d.js"><link rel="prefetch" href="/assets/js/82.d6b092b3.js"><link rel="prefetch" href="/assets/js/83.480ad2a7.js"><link rel="prefetch" href="/assets/js/84.9ccf3129.js"><link rel="prefetch" href="/assets/js/85.d3b4c265.js"><link rel="prefetch" href="/assets/js/86.a9d37445.js"><link rel="prefetch" href="/assets/js/87.87970e32.js"><link rel="prefetch" href="/assets/js/88.ae6c8b1a.js"><link rel="prefetch" href="/assets/js/89.004ff48b.js"><link rel="prefetch" href="/assets/js/9.ea9f0c60.js"><link rel="prefetch" href="/assets/js/90.574ad6dc.js"><link rel="prefetch" href="/assets/js/91.919f7599.js"><link rel="prefetch" href="/assets/js/92.0403f50b.js"><link rel="prefetch" href="/assets/js/93.f1c10d6e.js"><link rel="prefetch" href="/assets/js/94.68180157.js"><link rel="prefetch" href="/assets/js/95.43aaa156.js"><link rel="prefetch" href="/assets/js/96.5c07dd45.js"><link rel="prefetch" href="/assets/js/97.34e6505b.js"><link rel="prefetch" href="/assets/js/98.ee88afe4.js"><link rel="prefetch" href="/assets/js/99.d636b596.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d72a9179.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">TigerZ Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/navigation/" class="nav-link">导航站</a></div><div class="nav-item"><a href="/pages/585994/" class="nav-link">科研技能</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文献阅读" class="dropdown-title"><a href="/pages/577e62/" class="link-title">文献阅读</a> <span class="title" style="display:none;">文献阅读</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/09e806/" class="nav-link">作者汇总</a></li><li class="dropdown-subitem"><a href="/pages/4c56e7/" class="nav-link">文献汇总</a></li></ul></li><li class="dropdown-item"><h4>分类</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/17c432/" class="nav-link">神经生物学</a></li><li class="dropdown-subitem"><a href="/pages/e2e6a4/" class="nav-link">单细胞空间组</a></li><li class="dropdown-subitem"><a href="/pages/e90196/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/69dc52/" class="nav-link">生物信息学</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生信学习" class="dropdown-title"><a href="/pages/98350d/" class="link-title">生信学习</a> <span class="title" style="display:none;">生信学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/11a817/" class="nav-link">生信工具汇总</a></li></ul></li><li class="dropdown-item"><h4>生信工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/967a30/" class="nav-link">单细胞和空间组</a></li><li class="dropdown-subitem"><a href="/pages/3c3418/" class="nav-link">机器学习</a></li><li class="dropdown-subitem"><a href="/pages/726c78/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/8b01b8/" class="nav-link">图像处理</a></li><li class="dropdown-subitem"><a href="/pages/c3f74c/" class="nav-link">NGS相关</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Web开发" class="dropdown-title"><a href="/pages/4efbc6/" class="link-title">Web开发</a> <span class="title" style="display:none;">Web开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/3ca8f4/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/pages/f16f8d/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/pages/9ec206/" class="nav-link">JS/TS</a></li><li class="dropdown-subitem"><a href="/pages/1abc5f/" class="nav-link">Markdown</a></li><li class="dropdown-subitem"><a href="/pages/d2038c/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/pages/d4684b/" class="nav-link">Ajax</a></li></ul></li><li class="dropdown-item"><h4>后端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/98c9ed/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/pages/e1436c/" class="nav-link">Django</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据分析" class="dropdown-title"><a href="/pages/3c0f51/" class="link-title">数据分析</a> <span class="title" style="display:none;">数据分析</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/01057a/" class="nav-link">数学基础</a></li><li class="dropdown-item"><h4>机器学习</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/99a1ec/" class="nav-link">机器学习 - 西瓜书</a></li><li class="dropdown-subitem"><a href="/pages/7daf99/" class="nav-link">机器学习 - 吴恩达</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程学习" class="dropdown-title"><a href="/pages/baed44/" class="link-title">编程学习</a> <span class="title" style="display:none;">编程学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/9ab953/" class="nav-link">R 汇总</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生物知识" class="dropdown-title"><a href="/pages/634e82/" class="link-title">生物知识</a> <span class="title" style="display:none;">生物知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>神经生物学</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/be5d67/" class="nav-link">《神经生物学》- 丁斐</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生活" class="dropdown-title"><a href="/pages/d28eb7/" class="link-title">生活</a> <span class="title" style="display:none;">生活</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/eccd67/" class="nav-link">观影</a></li><li class="dropdown-item"><!----> <a href="/pages/30653b/" class="nav-link">摘抄</a></li><li class="dropdown-item"><!----> <a href="/pages/1a58a6/" class="nav-link">音乐</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="关于" class="dropdown-title"><a href="/pages/8cb41f/" class="link-title">关于</a> <span class="title" style="display:none;">关于</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/13ae7d/" class="nav-link">关于 - 自我</a></li><li class="dropdown-item"><!----> <a href="/pages/2b095a/" class="nav-link">关于 - 本站</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">关于 - 归档</a></li></ul></div></div><div class="nav-item"><a href="/message-area/" class="nav-link">留言区</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="img/avatar.jpg"> <div class="blogger-info"><h3>TigerZ</h3> <span>一个努力学习的小菜鸡</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/navigation/" class="nav-link">导航站</a></div><div class="nav-item"><a href="/pages/585994/" class="nav-link">科研技能</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="文献阅读" class="dropdown-title"><a href="/pages/577e62/" class="link-title">文献阅读</a> <span class="title" style="display:none;">文献阅读</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/09e806/" class="nav-link">作者汇总</a></li><li class="dropdown-subitem"><a href="/pages/4c56e7/" class="nav-link">文献汇总</a></li></ul></li><li class="dropdown-item"><h4>分类</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/17c432/" class="nav-link">神经生物学</a></li><li class="dropdown-subitem"><a href="/pages/e2e6a4/" class="nav-link">单细胞空间组</a></li><li class="dropdown-subitem"><a href="/pages/e90196/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/69dc52/" class="nav-link">生物信息学</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生信学习" class="dropdown-title"><a href="/pages/98350d/" class="link-title">生信学习</a> <span class="title" style="display:none;">生信学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/11a817/" class="nav-link">生信工具汇总</a></li></ul></li><li class="dropdown-item"><h4>生信工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/967a30/" class="nav-link">单细胞和空间组</a></li><li class="dropdown-subitem"><a href="/pages/3c3418/" class="nav-link">机器学习</a></li><li class="dropdown-subitem"><a href="/pages/726c78/" class="nav-link">三维基因组</a></li><li class="dropdown-subitem"><a href="/pages/8b01b8/" class="nav-link">图像处理</a></li><li class="dropdown-subitem"><a href="/pages/c3f74c/" class="nav-link">NGS相关</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Web开发" class="dropdown-title"><a href="/pages/4efbc6/" class="link-title">Web开发</a> <span class="title" style="display:none;">Web开发</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/3ca8f4/" class="nav-link">HTML</a></li><li class="dropdown-subitem"><a href="/pages/f16f8d/" class="nav-link">CSS</a></li><li class="dropdown-subitem"><a href="/pages/9ec206/" class="nav-link">JS/TS</a></li><li class="dropdown-subitem"><a href="/pages/1abc5f/" class="nav-link">Markdown</a></li><li class="dropdown-subitem"><a href="/pages/d2038c/" class="nav-link">Vue</a></li><li class="dropdown-subitem"><a href="/pages/d4684b/" class="nav-link">Ajax</a></li></ul></li><li class="dropdown-item"><h4>后端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/98c9ed/" class="nav-link">MySQL</a></li><li class="dropdown-subitem"><a href="/pages/e1436c/" class="nav-link">Django</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据分析" class="dropdown-title"><a href="/pages/3c0f51/" class="link-title">数据分析</a> <span class="title" style="display:none;">数据分析</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/01057a/" class="nav-link">数学基础</a></li><li class="dropdown-item"><h4>机器学习</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/99a1ec/" class="nav-link">机器学习 - 西瓜书</a></li><li class="dropdown-subitem"><a href="/pages/7daf99/" class="nav-link">机器学习 - 吴恩达</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="编程学习" class="dropdown-title"><a href="/pages/baed44/" class="link-title">编程学习</a> <span class="title" style="display:none;">编程学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>汇总</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/9ab953/" class="nav-link">R 汇总</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生物知识" class="dropdown-title"><a href="/pages/634e82/" class="link-title">生物知识</a> <span class="title" style="display:none;">生物知识</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>神经生物学</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/be5d67/" class="nav-link">《神经生物学》- 丁斐</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="生活" class="dropdown-title"><a href="/pages/d28eb7/" class="link-title">生活</a> <span class="title" style="display:none;">生活</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/eccd67/" class="nav-link">观影</a></li><li class="dropdown-item"><!----> <a href="/pages/30653b/" class="nav-link">摘抄</a></li><li class="dropdown-item"><!----> <a href="/pages/1a58a6/" class="nav-link">音乐</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="关于" class="dropdown-title"><a href="/pages/8cb41f/" class="link-title">关于</a> <span class="title" style="display:none;">关于</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/13ae7d/" class="nav-link">关于 - 自我</a></li><li class="dropdown-item"><!----> <a href="/pages/2b095a/" class="nav-link">关于 - 本站</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">关于 - 归档</a></li></ul></div></div><div class="nav-item"><a href="/message-area/" class="nav-link">留言区</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>神经生物学</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>单细胞空间组</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>三维基因组</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>生物信息学</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/ffdcc0/" class="sidebar-link">文献阅读 --- WGCNA：an R package for weighted correlation network analysis</a></li><li><a href="/pages/0d1fce/" class="sidebar-link">文献阅读 --- Spatial reconstruction of single-cell gene expression data</a></li><li><a href="/pages/e020de/" class="sidebar-link">文献阅读 --- An interactive framework for whole-brain maps at cellular resolution</a></li><li><a href="/pages/ebb632/" class="sidebar-link">文献阅读 --- SCANPY：large-scale single-cell gene expression data analysis</a></li><li><a href="/pages/f37280/" class="sidebar-link">文献阅读 --- Integrating single-cell transcriptomic data across different conditions, technologies, and species</a></li><li><a href="/pages/06c5a0/" class="sidebar-link">文献阅读 --- Recovering Gene Interactions from Single-Cell Data Using Data Diffusion</a></li><li><a href="/pages/71b694/" class="sidebar-link">文献阅读 --- DoubletFinder:Doublet Detection in Single-Cell RNA Sequencing Data Using Artificial Nearest Neighbors</a></li><li><a href="/pages/d26f9e/" class="sidebar-link">文献阅读 --- Comprehensive Integration of Single-Cell Data</a></li><li><a href="/pages/c7adb0/" class="sidebar-link">文献阅读 --- A systematic evaluation of single-cell RNA-sequencing imputation methods</a></li><li><a href="/pages/d38252/" aria-current="page" class="active sidebar-link">文献阅读 --- nnU-Net：a self-configuring method for deep learning-based biomedical image segmentation</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/d38252/#abstract" class="sidebar-link">Abstract</a></li><li class="sidebar-sub-header level2"><a href="/pages/d38252/#introduction" class="sidebar-link">Introduction</a></li><li class="sidebar-sub-header level2"><a href="/pages/d38252/#results" class="sidebar-link">Results</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/d38252/#fig-1-nnu-net-handles-a-broad-variety-of-datasets-and-target-image-properties" class="sidebar-link">Fig.1 nnU-Net handles a broad variety of datasets and target image properties</a></li><li class="sidebar-sub-header level3"><a href="/pages/d38252/#fig-2-proposed-automated-method-configuration-for-deep-learning-based-biomedical-image-segmentation" class="sidebar-link">Fig.2 Proposed automated method configuration for deep learning-based biomedical image segmentation</a></li><li class="sidebar-sub-header level3"><a href="/pages/d38252/#fig-3-nnu-net-outperforms-most-specialized-deep-learning-pipelines" class="sidebar-link">Fig.3 nnU-Net outperforms most specialized deep learning pipelines</a></li><li class="sidebar-sub-header level3"><a href="/pages/d38252/#fig-4-pipeline-fingerprints-from-kits-2019-leaderboard-entries" class="sidebar-link">Fig.4 Pipeline fingerprints from KiTS 2019 leaderboard entries</a></li><li class="sidebar-sub-header level3"><a href="/pages/d38252/#fig-5-data-fingerprints-across-different-challenge-datasets" class="sidebar-link">Fig.5 Data fingerprints across different challenge datasets</a></li><li class="sidebar-sub-header level3"><a href="/pages/d38252/#fig-6-evaluation-of-design-decisions-across-multiple-tasks" class="sidebar-link">Fig.6 Evaluation of design decisions across multiple tasks</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/d38252/#discussion" class="sidebar-link">Discussion</a></li></ul></li><li><a href="/pages/c34d2c/" class="sidebar-link">文献阅读 --- GCNG：graph convolutional networks for inferring gene interaction from spatial transcriptomics data</a></li><li><a href="/pages/1f3ea0/" class="sidebar-link">文献阅读 --- Cellpose：a generalist algorithm for cellular segmentation</a></li><li><a href="/pages/1f53c5/" class="sidebar-link">文献阅读 --- FAN-C:a feature-rich framework for the analysis and visualisation of chromosome conformation capture data</a></li><li><a href="/pages/1c1b2b/" class="sidebar-link">文献阅读 --- Toward data-efficient learning：A benchmark for COVID-19 CT lung and infection segmentation</a></li><li><a href="/pages/2737d2/" class="sidebar-link">文献阅读 --- Inference and analysis of cell-cell communication using CellChat</a></li><li><a href="/pages/b4dfe0/" class="sidebar-link">文献阅读 --- Integrated analysis of multimodal single-cell data</a></li><li><a href="/pages/6a4bcc/" class="sidebar-link">文献阅读 --- Discovery and Validation of Key Biomarkers Based on Immune Infiltrates in Alzheimer's Disease</a></li><li><a href="/pages/c3bbd9/" class="sidebar-link">文献阅读 --- Deep learning and alignment of spatially resolved single-cell transcriptomes with Tangram</a></li><li><a href="/pages/9912cc/" class="sidebar-link">文献阅读 --- Cell2location maps fine-grained cell types in spatial transcriptomics</a></li><li><a href="/pages/76476f/" class="sidebar-link">文献阅读 --- Squidpy：a scalable framework for spatial omics analysis</a></li><li><a href="/pages/112d0b/" class="sidebar-link">文献阅读 --- Viv：multiscale visualization of high-resolution multiplexed bioimaging data on the web</a></li><li><a href="/pages/4cba92/" class="sidebar-link">文献阅读 --- SpaceX：gene co-expression network estimation for spatial transcriptomics</a></li><li><a href="/pages/794f06/" class="sidebar-link">文献阅读 --- Inferring neuron-neuron communications from single-cell transcriptomics through NeuronChat</a></li><li><a href="/pages/8c5839/" class="sidebar-link">文献阅读 --- Dictionary learning for integrative, multimodal and scalable single-cell analysis</a></li><li><a href="/pages/124edd/" class="sidebar-link">文献阅读 --- The scverse project provides a computational ecosystem for single-cell omics data analysis</a></li><li><a href="/pages/a24249/" class="sidebar-link">文献阅读 --- hdWGCNA identifies co-expression networks in high-dimensional transcriptomics data</a></li><li><a href="/pages/da0fb5/" class="sidebar-link">文献阅读 --- SPACEL：deep learning-based characterization of spatial transcriptome architectures</a></li><li><a href="/pages/32a729/" class="sidebar-link">文献阅读 --- The tidyomics ecosystem：enhancing omic data analyses</a></li><li><a href="/pages/02ef79/" class="sidebar-link">文献阅读 --- ezSingleCell：an integrated one-stop single-cell and spatial omics analysis platform for bench scientists</a></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper bg-style-1"><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/pages/577e62/#文献阅读" data-v-06225672>文献阅读</a></li><li data-v-06225672><a href="/pages/577e62/#生物信息学" data-v-06225672>生物信息学</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://zhenghu159.github.io/" target="_blank" title="作者" class="beLink" data-v-06225672>TigerZ </a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-04-07</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">文献阅读 --- nnU-Net：a self-configuring method for deep learning-based biomedical image segmentation<!----></h1>  <div class="theme-vdoing-content content__default"><p>题目: nnU-Net: 一种基于深度学习的生物医学图像分割的自配置方法<br>
DOI: <a href="https://doi.org/10.1038/s41592-020-01008-z" target="_blank" rel="noopener noreferrer">https://doi.org/10.1038/s41592-020-01008-z<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br>
Cite: Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. <em>Nat Methods</em> 18, 203–211 (2021).</p> <div class="custom-block note"><p class="custom-block-title">相关阅读</p> <p>微信公众号：<a href="https://mp.weixin.qq.com/s?__biz=MzkwMjM0MzA5MA==&amp;mid=2247484054&amp;idx=1&amp;sn=cae057ebd0e0842c95a190899e55bc87&amp;chksm=c0a7b24bf7d03b5d6304cb547fb771ba11cc59d9862169a8e1fb71e0b98400c181da1baf53fc&amp;token=1421997773&amp;lang=zh_CN#rd" target="_blank" rel="noopener noreferrer">文献阅读：nnU-Net: 一种基于深度学习的生物医学图像分割的自配置方法<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <br> <br>
站内文章：</p> <ol><li><a href="https://tigerz.online/pages/d38252/" target="_blank" rel="noopener noreferrer">文献阅读 --- nnU-Net：a self-configuring method for deep learning-based biomedical image segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://tigerz.online/pages/1c1b2b/" target="_blank" rel="noopener noreferrer">文献阅读 --- Toward data-efficient learning：A benchmark for COVID-19 CT lung and infection segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://tigerz.online/pages/8633a5/" target="_blank" rel="noopener noreferrer">nnUNet：a self-configuring method for deep learning-based biomedical image segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ol></div> <p><strong>作者介绍：</strong></p> <table><thead><tr><th style="text-align:center;">Klaus H. Maier-Hein</th></tr></thead> <tbody><tr><td style="text-align:center;"><img src="https://www.dkfz.de/__we_thumbs__/72316_12_Klaus1.png" width="200"></td></tr> <tr><td style="text-align:center;">German Cancer Research Center</td></tr> <tr><td style="text-align:center;"><a href="mailto:k.maier-hein@dkfz.de">k.maier-hein@dkfz.de</a></td></tr></tbody></table> <h2 id="abstract"><a href="#abstract" class="header-anchor">#</a> Abstract</h2> <p>生物医学成像是科学发现的推动者和医疗护理的核心组成部分，并受到深度学习领域的刺激。虽然语义分割算法在许多应用中实现了图像分析和量化，但各自专业化解决方案的设计并不简单，且高度依赖于数据集属性和硬件条件。我们开发了 nnU-Net，一种基于深度学习的分割方法，可以自动配置自己，包括预处理、网络架构、训练和后处理。这个过程中的关键设计选择被建模为一组固定参数、相互依赖的规则和经验决策。在没有手动干预的情况下，nnU-Net 超越了大多数现有方法，包括在23个国际生物医学分割竞赛中使用的高度专业化解决方案。我们将 nnU-Net 公开作为一种开箱即用的工具，通过不需要专业知识和超出标准网络训练之外的计算资源，使最先进的分割技术对广大受众可用。</p> <h2 id="introduction"><a href="#introduction" class="header-anchor">#</a> Introduction</h2> <p>语义分割将原始生物医学图像数据转化为有意义的、有空间结构的信息，因此在科学发现方面起着至关重要的作用。同时，语义分割也是许多临床应用的必要组成部分，包括人工智能在诊断支持系统、治疗计划支持、术中辅助和肿瘤生长监测等方面的应用。对自动分割方法的高度兴趣表现在蓬勃发展的研究领域中，该
领域占据国际生物医学图像分析竞赛的70%。</p> <p>尽管基于深度学习的分割方法最近取得了成功，但它们对终端用户的特定图像分析问题的适用性通常是有限的。方法的任务特定设计和配置需要高水平的专业知识和经验，小的误差会导致性能大幅下降。特别是在三维生物医学成像领域，数据集属性如成像模态、图像大小、（各向异性）像素间距和类比例等差异巨大，这个过程可能会很麻烦，并且一个数据集的成功配置很少能适用于另一个数据集。自适应和训练神经网络涉及许多专家决策，从确切的网络架构到训练计划和数据增强或后处理方法。每个相互依存的子组件都由关键参数（如学习率、批量大小或类别抽样策略）控制。此外，硬件可用性也增加了整体设置的复杂性。在这个高维空间中纯经验优化共同设计选择的方法，如先前在自动机器学习（AutoML）领域中所提出的，将所需的训练案例数量以及计算资源增加数倍，并且通常只涵盖分割管道的一小部分（例如架构或数据增强），留下了相当大比例的配置问题供试验者解决。此外，将 AutoML 应用于新数据集时还需要进行一系列必要的专家选择，例如在考虑构建合理的问题特定搜索空间时。我们对国际生物医学分割挑战的现状进行的分析表明，这些实际限制通常会让用户在方法设计过程中采用手动的、迭代的试错过程，该过程大多是由个人经验驱动的，只有少量的记录，并且经常导致亚优化的分割管道。</p> <p>在本工作中，我们概述了医学分割中主要由专家驱动的方法配置和主要由数据驱动的 AutoML 方法之间的新路径。具体来说，我们在此定义了一种配方，系统化了在任务无关级别上的配置过程，并在给定新任务时大大减少了经验设计选择的搜索空间。</p> <ol><li>收集那些不需要在数据集之间进行适应的设计决策，并确定一个健壮的通用配置（&quot;固定参数&quot;）。</li> <li>对于尽可能多的剩余决策，以启发式规则的形式，明确数据集属性（&quot;数据集指纹&quot;）和设计决策（&quot;管道指纹&quot;）之间的依赖关系，以实现在应用中的几乎即时适应（&quot;基于规则的参数&quot;）。</li> <li>仅从数据中学习剩余的决策（&quot;经验性参数&quot;）。</li></ol> <p>我们实现了这个方法，并在 Medical Segmentation Decathlon 提供的十个数据集上进行了验证。我们称其为 nnU-Net 的分割方法能够执行任意新数据集的自动配置。与现有研究方法相比，nnU-Net 是综合性的，即其自动配置涵盖了整个分割流程（包括网络体系结构的基本拓扑参数）而不需要任何手动决策。此外，nnU-Net 中的自动配置非常快，只需要执行简单的规则和做出少量经验性的选择，因此除了标准模型训练之外几乎不需要任何计算资源。最后，nnU-Net 是数据有效的；基于大量和多样化的数据池进行设计选择编码，为应用于训练数据有限的数据集提供了强有力的归纳偏差。</p> <p>nnU-Net 的自动配置的普适性在 13 个额外的数据集上得到了证明。总共，我们报告了 53 个分割任务的结果，涵盖了目标结构、图像类型和图像属性的前所未有的多样性。作为开源工具，nnU-Net 可以简单地进行训练，以生成最先进的分割。</p> <h2 id="results"><a href="#results" class="header-anchor">#</a> Results</h2> <p>nnU-Net 是一种基于深度学习的分割方法，可以自动配置自己，包括生物医学领域任何新任务的预处理、网络架构、训练和后处理。由 nnU-Net 对各种数据集生成的示范性分割结果如图 Fig.1 所示。</p> <h3 id="fig-1-nnu-net-handles-a-broad-variety-of-datasets-and-target-image-properties"><a href="#fig-1-nnu-net-handles-a-broad-variety-of-datasets-and-target-image-properties" class="header-anchor">#</a> Fig.1 nnU-Net handles a broad variety of datasets and target image properties</h3> <p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig1_HTML.png?as=webp" alt="Fig1"></p> <div class="custom-block note"><p class="custom-block-title">Fig1. nnU-Net 处理多种数据集和目标图像属性</p> <p>所有的例子都来自于 nnU-Net 所应用的不同国际分割挑战的测试集。每个数据集的目标结构显示在2D投影到原始数据上（左），3D显示在原始数据的卷渲染中（右）。所有的可视化操作都是使用 MITK Workbench 创建的。
<strong>a.</strong> CT 图像中的心脏（绿色）、主动脉（红色）、气管（蓝色）和食管（黄色）（dataset (D)18)。<br> <strong>b.</strong> FM 中的 A549 肺癌细胞（紫色）(D22)。<br> <strong>c.</strong> CT 图像中的肺结节（黄色）(D6)。<br> <strong>d.</strong> T1 in-phase MRI 中的肝脏（黄色）、脾脏（橙色）、左右肾（分别为蓝色和绿色）(D16)。<br> <strong>e.</strong> 电磁扫描中的突触裂隙（绿色）(D19) (https://cremi.org/)。<br> <strong>f.</strong> MRI 中的水肿（黄色）、增强肿瘤（紫色）、坏死（绿色）(T1, T1 with contrast agent, T2, FLAIR) (D1)。<br> <strong>g.</strong> CT 图像中的肾脏（黄色）和肾肿瘤（绿色）(D17)。<br> <strong>h.</strong> CT 图像显示 13 个腹部器官（D11）。 <br> <strong>i.</strong> CT显示肝血管（黄色）和肝肿瘤（绿色）（D8）。<br> <strong>j.</strong> MRI 显示左心室（黄色）(D2)。<br> <strong>k.</strong> cine MRI 中的右心室（黄色）、左心室腔（蓝色）和左心室心肌（绿色）(D13)。<br> <strong>l.</strong> FM 中的 HL60 细胞核（实例分割，每个实例一种颜色） (D21)。</p></div> <p><strong>nnU-Net 会自动适应任何新的数据集。</strong> Fig. 2 显示了 nnU-Net 如何系统地处理整个分割管道的配置，并提供了最相关的设计选择的可视化和描述。</p> <p>nnU-Net 的开发。nnU-Net 的自动配置基于将领域知识分为三个参数组：固定参数、基于规则的参数和经验参数。首先，我们收集所有不需要在数据集之间进行调整的设计决策（例如将体系结构模板设置为 &quot;U-Net-like&quot;），并优化它们的联合配置，以实现对开发数据集的稳健泛化。其次，对于尽可能多的剩余决策，我们制定了 'dataset fingerprint' 与 'pipeline fingerprint' 之间的明确依赖关系，其中 'dataset fingerprint' 是标准化的数据集表示，包括关键属性，如图像大小、像素间距信息或类别比例，而 'pipeline fingerprint' 则定义为在方法设计期间做出的所有选择的总和。这些依赖关系以相互依赖的启发式规则的形式建模，以实现几乎即时的执行。例如，批次大小、块大小和网络拓扑的相互配置基于以下三个原则。</p> <ul><li>较大的 batch size 可以提供更准确的梯度估计，因此更可取（通常在我们的领域中没有达到的一个最佳点），但实际上，任何大于 1 的 batch size 都会导致稳健的训练。</li> <li>在训练期间使用更大的 patch size 会增加网络吸收的上下文信息，因此对性能至关重要。</li> <li>网络的拓扑结构应该足够深，以保证有效的感受野大小至少与 patch size 一样大，这样就不会丢弃上下文信息。</li></ul> <p>将这些知识融合到成功的方法设计中，得到以下的启发式规则：&quot;将裁剪尺寸初始化为中位图像形状，然后在相应地调整网络拓扑结构（包括网络深度、每个轴上的池化操作的数量和位置、特征图大小和卷积核大小）的情况下逐步减小裁剪尺寸，直到在给定 GPU 内存限制的情况下可以使用至少两个批次大小进行训练。&quot; 在线方法中提供了所有启发式规则的详细描述，Supplementary Note 2 提供了用于推导规则的指导原则的编译。第三，我们只设置剩余的设计选择，即模型选择和后处理，在应用程序期间根据训练数据进行经验决策。我们将这种方法的实现称为 nnU-Net，它是专门在来自医学十项全能分割挑战赛的十个开发数据集上开发的。</p> <p>nnU-Net 应用。在将 nnU-Net 应用于新数据集时，nnU-Net 的自动配置在没有手动干预的情况下运行。因此，除了必须进行少量经验性选择外，不需要额外的计算成本，超出了标准网络训练程序所需的范围。nnU-Net 的自动方法配置始于提取数据集指纹和随后执行启发式规则。默认情况下，nnU-Net 生成三种不同的 U-Net 配置：一个二维（2D）U-Net，一个在完整图像分辨率下运行的三维（3D）U-Net，以及一个 3D U-Net cascade，其中第一个 U-Net 对降采样的图像进行操作，第二个 U-Net 被训练以在完整分辨率下细化前者创建的分割图。在交叉验证后，nnU-Net 经验性地选择最佳表现的配置或集成。最后，如果测量到性能提高，则 nnU-Net 经验性地选择 &quot;非最大组件抑制&quot; 作为后处理步骤。nnU-Net 自动配置和训练过程的输出是完全训练好的模型，可以部署以对未见过的图像进行预测。我们通过将其应用于 13 个附加数据集来展示编码在 nnU-Net 的固定、基于规则和经验性参数中的设计选择的泛化能力。</p> <p>nnU-Net 背后的方法学及其总体设计原则的详细描述分别在 Methods 和 Supplementary Note 2 中提供。nnU-Net 为所有数据集生成的分割流程在 Supplementary Note 6 中提供。</p> <h3 id="fig-2-proposed-automated-method-configuration-for-deep-learning-based-biomedical-image-segmentation"><a href="#fig-2-proposed-automated-method-configuration-for-deep-learning-based-biomedical-image-segmentation" class="header-anchor">#</a> Fig.2 Proposed automated method configuration for deep learning-based biomedical image segmentation</h3> <p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig2_HTML.png?as=webp" alt="Fig2"></p> <div class="custom-block note"><p class="custom-block-title">Fig2. 提出的基于深度学习的生物医学图像分割的自动方法配置</p> <p>给定一个新的分割任务，数据集属性以 'dataset fingerprint'（粉红色）的形式被提取。一组启发式规则建模参数的相互依赖关系（如细箭头所示），并对此指纹进行操作，以推断管道的数据依赖的 'rule-based parameters'（绿色）。这些都是由 'fixed parameters'（蓝色）补充的，这是预定义的，不需要适应。可以在 five-fold 交叉验证中训练最多三种配置。最后，nnU-Net 自动对这些模型的最优集成进行经验选择，并确定是否需要进行后处理('empirical parameters', 黄色)。底部的表显示了所有配置参数的显式值以及总结的规则公式。Res., resolution。</p></div> <p><strong>nnU-Net 可以处理各种目标结构和图像属性。</strong> 我们通过将其应用于 11 个国际生物医学图像分割挑战，包括 23 个不同的数据集和 53 个分割任务 (<a href="https://cremi.org/" target="_blank" rel="noopener noreferrer">https://cremi.org/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）， 展示了 nnU-Net 作为开箱即用的分割工具的价值。这个选择包括各种器官、器官亚结构、肿瘤、病变和 2D 及 3D 图像中的细胞结构，这些图像是通过磁共振成像（MRI）、计算机断层扫描（CT）、电子显微镜（EM）和荧光显微镜（FM）获取的。 'Challenges' 是国际比赛，旨在在标准化环境中评估多种算法的性能。在所有分割任务中，nnU-Net 仅使用提供的挑战数据从头开始进行训练。定性地，我们观察到 nnU-Net 可以处理数据集属性的大差异和目标结构的多样性；也就是说，生成的管道配置符合人类专家认为合理或明智的设置 (Supplementary Note 3, sections 1 and 2)。nnU-Net 生成的分割结果示例如 Fig. 1 所示。</p> <p><strong>nnU-Net 在各种不同任务中表现优于专业化的管道。</strong> Fig. 3 概述了 nnU-Net 和所有 53 个分割任务中竞争对手挑战团队所取得的定量结果。尽管其具有通用性，但 nnU-Net 表现优于大多数现有的分割解决方案，即使后者是专门针对各自的任务进行优化的。总体而言，nnU-Net 在 53 个目标结构中的 33 个中创造了新的技术水平，并在其它任务中表现与排名榜前列的竞争者相当或接近。</p> <h3 id="fig-3-nnu-net-outperforms-most-specialized-deep-learning-pipelines"><a href="#fig-3-nnu-net-outperforms-most-specialized-deep-learning-pipelines" class="header-anchor">#</a> Fig.3 nnU-Net outperforms most specialized deep learning pipelines</h3> <p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig3_HTML.png?as=webp" alt="Fig3"></p> <div class="custom-block note"><p class="custom-block-title">Fig3. nnU-Net 的性能优于大多数专业的深度学习管道</p> <p>来自 nnU-Net 竞争的所有国际挑战的定量结果。对于每个分割任务，nnU-Net 获得的结果用红色突出显示；竞争团队用蓝色表示。对于每个分割任务，nnU-Net 的排名和竞争算法的总数显示在每个图的右下角。请注意，对于混乱挑战 (D16)，由于 section 9 of Supplementary Note 6 中概述的原因，我们只参加了五个子任务中的两个。细胞追踪挑战排行榜 (D20-D23) 最后一次访问是在 2020 年 7 月 30 日；所有剩余的排行榜最后一次访问是在 2019 年 12 月 12 日。SIM, simulated。</p></div> <p><strong>方法配置中的细节对性能的影响比架构变化更大。</strong> 为了更深入地了解基于深度学习的生物医学图像分割的当前实践，我们以最近由医学图像计算和计算机辅助干预（MICCAI）协会举办的肾和肾肿瘤分割 (KiTS) 2019挑战赛的参赛算法为例进行分析。MICCAI 协会一直主办着至少 50% 的年度生物医学图像分析挑战赛。KiTS挑战赛是 MICCAI 2019 中最大的比赛，有 100 多个竞争对手。首先观察到的是，自动机器学习方法明显缺席于排行榜之上。仅有一个提交 (rank 18 of 100) 报告了通过网格搜索选择 &quot;一些超数&quot;（<a href="http://results.kits-challenge.org/miccai2019/manuscripts/peekaboo_2.pdf" target="_blank" rel="noopener noreferrer">http://results.kits-challenge.org/miccai2019/manuscripts/peekaboo_2.pdf<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>），而手动试错优化代表了不可否认的现状。值得注意的是，这一观察结果不仅仅适用于 KiTS；我们不知道任何成功的生物医学图像分割竞赛提交采用了自动机器学习方法。Fig. 4a 提供了 KiTS 排行榜的总体概述（<a href="http://results.kits-challenge.org/miccai2019" target="_blank" rel="noopener noreferrer">http://results.kits-challenge.org/miccai2019<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>），揭示了基于深度学习的分割方法设计的当前情况。首先，前 15 种方法都是基于 2016 年的（3D）U-Net 架构派生而来，证实了它对生物医学图像分割领域的影响。其次，使用相同类型的网络的贡献导致表现遍布整个排行榜。第三，在检查前 15 种方法时，常用的架构修改（例如，残差连接，密集连接，注意力机制或空洞卷积）没有代表 KiTS 任务的良好表现的必要条件。</p> <p>Fig. 4b 强调了找到好的方法配置的重要性。它展示了使用与挑战获胜贡献相同的架构变体的算法的分析，即带有残差连接的 3D U-Net。虽然其中一种方法赢得了挑战，但其他基于相同原理的贡献则涵盖了整个评估分数和排名范围。关键配置参数是从各自的管道指纹中选择的，说明每个团队在方法配置期间所做的相互依赖的设计选择。参赛者提交的截然不同的配置表明了为生物医学图像分割配置深度学习方法所隐含的高维优化问题的复杂性。</p> <p>nnU-Net 实验通过在 KiTS 数据集上设置一个新的最佳结果，实验证明了方法配置相对于架构变化的相对重要性。该结果是通过使用普通的 3D U-Net 架构在开放的 leaderboard 上获得的。需要注意的是，nnU-Net 在原始比赛结束后才被提交到 leaderboard 上，因此它不是原始 leaderboard 分析的一部分。这个观察结果与我们在其他 22 个数据集上的结果一致 (Fig. 3)。</p> <h3 id="fig-4-pipeline-fingerprints-from-kits-2019-leaderboard-entries"><a href="#fig-4-pipeline-fingerprints-from-kits-2019-leaderboard-entries" class="header-anchor">#</a> Fig.4 Pipeline fingerprints from KiTS 2019 leaderboard entries</h3> <p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig4_HTML.png?as=webp" alt="Fig4"></p> <div class="custom-block note"><p class="custom-block-title">Fig4. 来自 KiTS 2019 排行榜记录的管道指纹</p> <p><strong>a.</strong> 根据架构变化对排行榜条目进行粗略分类。所有前15个贡献都是具有跳过连接、3D卷积和输出步幅1的编解码器架构（&quot;3DU-Net-like&quot;，紫色）。<br> <strong>b.</strong> 从所有具有剩余连接的非级联 3D U-net 类架构的管道指纹中选择更细粒度的关键参数（显示在 z-score 标准化尺度上）。缩写，CE, cross-entropy loss function; Dice, soft Dice loss function; WBCE, weighted binary CE。关于 KiTS 2019 challenge 的进一步信息，请访问 <a href="http://results.kits-challenge.org/" target="_blank" rel="noopener noreferrer">http://results.kits-challenge.org/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>。</p></div> <p><strong>不同的数据集需要不同的管道配置。</strong> 我们提取了 23 个生物医学分割数据集的数据指纹。如 Fig. 5 所示，这记录了生物医学成像中异常的数据集多样性，并揭示了无开箱即用分割算法的根本原因：方法配置的复杂性受到数据指纹的影响，这些数据指纹可能存在潜在的复杂关系。因此，针对一个数据集确定的管道设置（例如KiTS，见上文）可能无法推广到其他数据集，需要针对每个单独的数据集进行重新优化。nnU-Net 通过确定稳健的设计决策并明确建模关键相互依赖关系来应对这一挑战（Fig. 2）。</p> <h3 id="fig-5-data-fingerprints-across-different-challenge-datasets"><a href="#fig-5-data-fingerprints-across-different-challenge-datasets" class="header-anchor">#</a> Fig.5 Data fingerprints across different challenge datasets</h3> <p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig5_HTML.png?as=webp" alt="Fig5"></p> <div class="custom-block note"><p class="custom-block-title">Fig5. 不同挑战数据集上的数据指纹</p> <p>数据指纹显示关键属性(在一个 s.d. 的尺度上以 z-score 标准化显示。在 nnU-Net 实验中使用的 23 个数据集上 (see Supplementary Note 1 for detailed dataset descriptions)。</p></div> <p><strong>多个任务能够实现强大的设计决策。</strong> nnU-Net 的自动方法配置可以被研究人员利用来开发新的分割方法。新颖的想法可以轻松地集成到 nnU-Net 中，并因此在多个数据集上进行测试，无需为每个数据集手动重新配置整个流程。为了展示这种方法的优点，同时也支持 nnU-Net 中的一些核心设计选择，我们通过系统修改一些nnU-Net 的固定参数，系统地测试了常见流程变化的性能。以下变化在十个不同的数据集上进行了评估，并与我们的默认 nnU-Net 配置进行了比较，该配置作为这些实验的基线（Fig. 6）。</p> <p>数据集排名的不稳定性表明，单个设计选择可以根据数据集而影响分割性能。结果清楚地表明，在基于不足数量的数据集进行评估时，需要谨慎地从中得出方法论结论。虽然九个变体中的五个在至少一个数据集中排名第一，但它们中没有一个在十个任务中展现出一致的改进。原始 nnU-Net 配置展现了最好的泛化性能，并在对所有数据集的结果进行汇总时排名第一。</p> <h3 id="fig-6-evaluation-of-design-decisions-across-multiple-tasks"><a href="#fig-6-evaluation-of-design-decisions-across-multiple-tasks" class="header-anchor">#</a> Fig.6 Evaluation of design decisions across multiple tasks</h3> <p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41592-020-01008-z/MediaObjects/41592_2020_1008_Fig6_HTML.png?as=webp" alt="Fig6"></p> <div class="custom-block note"><p class="custom-block-title">Fig6. 对跨多个任务的设计决策的评估</p> <p><strong>a-j.</strong> 对来自医学分割十项全能的 10 个数据集的示范性模型变化的评估(D1–D10, see Fig. 5 for dataset references)：在这项研究中，我们应用了两种备选的损失函数（cross-entropy and TopK10），在编码器中引入了残差连接，使用了三个而不是两个卷积层每个分辨率（导致了更深的网络架构），两种优化器的修改（降低了动量项和使用另一种优化器（Adam）），使用了批归一化而不是实例归一化，以及省略了数据增强（关于进一步设计选择的削弱实验可以在Supplementary Note 8 中找到）。对于每个数据集，通过将五折交叉验证的验证拆分聚合到一个大的验证集中来估计排名稳定性。通过自助法（有放回地抽样）生成了一千个虚拟验证集。在每个虚拟验证集上对算法进行排名，从而得到一个排名分布，如 challengeR 工具所建议的那样。<br> <strong>k.</strong> 跨数据集的排名聚合产生了对设计决策稳健泛化的见解。</p></div> <h2 id="discussion"><a href="#discussion" class="header-anchor">#</a> Discussion</h2> <p>我们介绍了 nnU-Net，这是一种基于深度学习的分割方法，可自动配置包括预处理、网络架构、训练和后处理在内的任何新的生物医学任务。nnU-Net 在大多数任务上都取得了新的最先进成果，优于所有相应的专业处理流程。nnU-Net 的强大性能不是通过新的网络架构、损失函数或训练方案实现的（因此得名 nnU-Net，“没有新网络”），而是通过系统化手动方法配置的复杂过程，该过程先前要么通过繁琐的手动调整，要么通过具有实际限制的纯经验方法来解决。我们假设 nnU-Net 的最先进性能的原因在于将大量数据集的知识浓缩成一组稳健的设计选择，这在应用于新数据集时转化为强大的归纳偏差，使其具有超越在单个数据集上配置的模型的泛化能力。此外，通过将领域知识浓缩成一组固定的、基于规则和经验的参数，我们概述了一条新的路径，用于自动化方法配置，这在计算上是可行的，同时覆盖整个分割管道，包括网络架构的重要拓扑参数。nnU-Net  是一种新的分割工具，可以开箱即用，无需任何用户干预，适用于广泛的生物医学成像数据集，因此非常适合需要访问语义分割方法的用户，他们没有适应现有解决方案所需的专业知识、时间、数据或计算资源。</p> <p>我们对 KiTS 排行榜的分析揭示了生物医学图像分割中方法配置的手工和不够系统的现状，并为该领域的当前研究提供了一些启示。例如，我们观察到使用相同类型网络的贡献在整个排行榜中表现分散（Fig. 4），这与 Litjens et al. 的研究结果一致，他们在其综述中发现 &quot;许多研究人员使用完全相同的架构&quot;，&quot;但结果差异很大&quot;。文献提出的架构扩展可能无法适用于该领域中的所有数据集，原因可能有几个。首先，生物医学领域的数据集多样性要求有专门的方法配置（Fig. 5）。因此，对新数据集进行的方法配置质量可能会掩盖评估的架构修改的效果。这一解释与 Litjens et al. 的观察一致，他们得出结论：&quot;精确的架构不是获得良好解决方案的最重要的决定因素&quot;，并且得到了 nnU-Net 在强大的方法配置和简单的 U-Net 架构组合下实现最先进结果的支持。其次，在当前的研究实践中，评估很少在两个以上的数据集上进行，即使是这样，数据集之间的属性也有很大重叠（例如，都是腹部 CT 扫描）。正如我们的多数据集研究所示（Fig. 6），这样的评估不适合得出一般的方法论结论。我们将不足够广泛的评估与手动调整所需的大量努力以及将提出的方法和现有管道（即基线）适应到个别数据集中的亚优配置基线联系起来。至关重要的是，这种繁琐的过程也可能导致基线配置次优，从而导致文献的潜在偏见。nnU-Net 能够缓解当前研究中的这些瓶颈。一方面，nnU-Net 是一种新的方法，不需要手动进行任务特定的适应，因此可以在任何新的分割任务上作为强大且标准化的基线。另一方面，nnU-Net 可以作为可扩展的实验框架，帮助研究人员轻松实现方法论修改，从而增加在该领域中用于评估的数据集数量。</p> <p>虽然 nnU-Net 被证明可以在新数据集上稳健地找到高质量的配置，但任务特定的经验优化可能有潜力进一步提高分割性能。然而，正如介绍中所详述的，经验 AutoML 方法的实际限制目前妨碍了它们在生物医学图像分割中的应用。另一个限制是与数据驱动优化相关的缺乏透明度（与 nnU-Net 相比，&quot;black box algorithms&quot;），因为由于基本的指导原则，每个设计决策都可以追溯到某些数据集属性或有限的经验实验。展望未来，我们认为我们的工作是补充经验 AutoML 研究的；nnU-Net 可以作为整体自动化的基础，可以通过选择设计决策（如数据增强或网络架构）的经验优化来增强。</p> <p>尽管在 53 个不同任务中 nnU-Net 表现出强大的性能，但仍可能存在一些分割任务，nnU-Net 的自动适应不是最优的。例如，nnU-Net 的开发重点是 Dice 系数作为性能度量。然而，某些任务可能需要高度特定于领域的目标度量来评估，这可能会影响方法设计。此外，可能存在未考虑的数据集属性，这可能会导致次优的分割性能。其中一个例子是 CREMI 挑战的突触裂隙分割任务(<a href="https://cremi.org" target="_blank" rel="noopener noreferrer">https://cremi.org<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>)。虽然 nnU-Net 的性能非常有竞争力(排名39个参赛者中的第6)，但手动调整损失函数以及 EM 特定的预处理可能是超越最先进性能所必需的。原则上，处理尚未充分覆盖的情况有两种方法。对于可能经常发生的情况，可以相应地扩展 nnU-Net 的启发式方法；对于高度特定于领域的情况，应将 nnU-Net 视为必要修改的良好起点。</p> <p>总的来说，nnU-Net 在各种语义分割挑战中树立了新的技术水平，并显示出强大的泛化特性，无需专业知识或超出标准网络训练的计算资源。正如 Litjens et al. 所指出并在此得到量化确认的那样，生物医学成像中的方法配置曾被认为是一种 &quot;高度经验性的练习&quot;，&quot;没有明确的配方&quot;。基于本文提出的配方，nnU-Net 能够自动化这种经常缺乏系统性和繁琐的过程，从而有助于减轻这一负担。我们建议将 nnU-Net 作为开箱即用的工具，用于最先进的分割、用于标准化和数据集不可知的比较基线，以及用于对新想法进行大规模评估而无需手动努力的框架。</p></div></div>  <div class="page-edit"><!----> <div class="tags"><a href="/tags/?tag=%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6" title="标签">#生物信息学</a></div> <div class="last-updated"><span class="prefix">更新时间:</span> <span class="time">2023/08/17, 09:47:20</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/c7adb0/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">文献阅读 --- A systematic evaluation of single-cell RNA-sequencing imputation methods</div></a> <a href="/pages/c34d2c/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">文献阅读 --- GCNG：graph convolutional networks for inferring gene interaction from spatial transcriptomics data</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/c7adb0/" class="prev">文献阅读 --- A systematic evaluation of single-cell RNA-sequencing imputation methods</a></span> <span class="next"><a href="/pages/c34d2c/">文献阅读 --- GCNG：graph convolutional networks for inferring gene interaction from spatial transcriptomics data</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/9912cc/"><div>
            文献阅读 --- Cell2location maps fine-grained cell types in spatial transcriptomics
            <!----></div></a> <span class="date">08-30</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/e020de/"><div>
            文献阅读 --- An interactive framework for whole-brain maps at cellular resolution
            <!----></div></a> <span class="date">08-30</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/521e00/"><div>
            文献阅读 --- Uncovering the genetic blueprint of the C. elegans nervous system
            <!----></div></a> <span class="date">08-30</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1308155474@qq.com" title="邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/zhenghu159" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://open.weixin.qq.com/qr/code?username=gh_55ff0104c230" title="微信" target="_blank" class="iconfont icon-weixin"></a><a href="https://www.zhihu.com/people/shu-ru-yong-hu-ming-65-69" title="知乎" target="_blank" class="iconfont icon-zhihu"></a><a href="https://www.jianshu.com/u/6dacd977dea9" title="简书" target="_blank" class="iconfont icon-jianshu"></a><a href="https://www.cnblogs.com/tigerzheng/" title="博客园" target="_blank" class="iconfont icon-bokeyuan"></a><a href="https://blog.csdn.net/weixin_45851732" title="CSDN" target="_blank" class="iconfont icon-csdn"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2024
    <span>TigerZ  | Blog<br> <a href="http://beian.miit.gov.cn/" target="_blank"></a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div> <!----> <!----></div><div class="global-ui"><div></div><div></div><div></div><div id="tcomment"></div><!----><canvas id="vuepress-canvas-cursor"></canvas><div></div></div></div>
    <script src="/assets/js/app.135a3dc6.js" defer></script><script src="/assets/js/2.b95133a4.js" defer></script><script src="/assets/js/121.9d3d53fd.js" defer></script><script src="/assets/js/14.330b018e.js" defer></script><script src="/assets/js/4.17f28c7e.js" defer></script><script src="/assets/js/8.113240f8.js" defer></script><script src="/assets/js/11.6804d4e2.js" defer></script>
  </body>
</html>
